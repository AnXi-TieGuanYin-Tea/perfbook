% intro/intro.tex

\chapter{Introduction}
\label{chp:Introduction}

\QuickQuizChapter{chp:Introduction}

Why is parallel programming hard?
One could list any number of reasons, ranging from deadlocks to race conditions
to testing coverage, but the real answer is that {\em it is not really
all that hard}.
After all, if parallel programming was really so horribly difficult,
how could a large number of open-source projects, ranging from Apache
to MySQL to the Linux kernel, have managed to master it?

A better question might be: ''Why is parallel programming {\em perceived}
to be so difficult?''
To see the answer, let's go back to the year 1991.
Paul McKenney was walking across the parking lot to Sequent's benchmarking
center carrying six dual-80486 Sequent Symmetry CPU boards, when he suddenly
realized that he was carrying several times the price of the house he had
just purchased.\footnote{
	Yes, this sudden realization {\em did} cause him to walk quite
	a bit more carefully.
	Why do you ask?}
This high cost of parallel systems meant that
parallel programming was restricted to a privileged few who
worked for an employer who either manufactured or could afford to
purchase machines costing upwards of \$100,000 --- in 1991 dollars US.

In contrast, in 2006, Paul finds himself typing these words on a
dual-core x86 laptop.
Unlike the dual-80486 CPU boards, this laptop also contains 2GB of
main memory, a 60GB disk drive, a display, Ethernet, USB ports, wireless,
and Bluetooth.
And the laptop is more than an order of magnitude cheaper than
even one of those dual-80486 CPU boards, even before taking inflation
into account.

Parallel systems have truly arrived.
They are no longer the sole domain of a privileged few, but something
available to almost everyone.

The earlier restricted availability of parallel hardware
is the \emph{real} reason that parallel programming is considered so difficult.
After all, it is quite difficult to learn to program even the simplest
machine if you have no access to it.
Since the age of rare and expensive parallel machines is for the most
part behind us, the age during which
parallel programming is perceived to be mind-crushingly difficult is
coming to a close.\footnote{
	Parallel programming is in some ways more difficult than sequential
	programming, for example, parallel validation is more difficult.
	But no longer mind-crushingly difficult.}

The purpose of this book is to help you understand how to program
shared-memory parallel machines without risking your sanity.\footnote{
	Or, perhaps more accurately, without much greater risk to your
	sanity than that incurred by non-parallel programming.
	Which, come to think of it, might not be saying all that much.
	Either way, Appendix~\ref{cha:app:Important Questions} discusses
	some important questions whose answers are less intuitive in
	parallel programs than they are in sequential program.}
By describing the algorithms and designs that have worked well in
the past, we hope to help you avoid at least some of the pitfalls
that have beset parallel projects.
But you should think of this book as a foundation on which to build,
rather than as a completed cathedral.
You mission, if you choose to accept, is to help make further progress
in the exciting field of parallel programming, progress that should
in time render this book obsolete.

\section{Goals: Performance, Scalability, Low Latency}
\label{sec:intro:Goals: Performance, Scalability, Low Latency}

What should your goals be when programming parallel systems?
Clearly, completing a correctly running program is always job 1.

But if performance is not a concern, you should instead do yourself
a favor and just write single-threaded code.
It will be easier, and you will probably get done much more quickly.

However, Moore's Law has ceased to provide its traditional performance
benefits, as can be seen in
Figure~\ref{fig:intro:Clock-Frequency Trend for Intel CPUs}.
This means that writing single-threaded code and simply waiting
a years or two for the CPUs to catch up may no longer be an option.
Given the recent trends on the part of all major manufacturers towards
multicore/multithreaded systems, parallelism is the way to go for
those wanting the avail themselves of the full performance of their
systems.

\begin{figure}[htb]
\begin{center}
\resizebox{3in}{!}{\includegraphics{SMPdesign/clockfreq}}
\end{center}
\caption{Clock-Frequency Trend for Intel CPUs}
\label{fig:intro:Clock-Frequency Trend for Intel CPUs}
\end{figure}

Even so, the first goal is performance rather than scalability,
especially given that the easiest way to attain linear scalability
is to reduce the performance of each CPU~\cite{LinusTorvalds2001a}.
Given a four-CPU system, which would you prefer?
A program that provides 100 transactions per second on a single CPU,
but does not scale at all?
Or a program that provides 10 transactions per second on a single CPU,
but scales perfectly?
The first program seems like a better bet, though the answer might
change if you happened to be one of the lucky few with access to a
32-CPU system.

Therefore, correctness first, performance second,
and scalability only as needed to
attain the required performance on whatever hardware your program
is to run on.

\input{intro/primitives}
\input{intro/hwhabits}

\section{Ease of Use}
\label{sec:intro:Ease of Use}

We are talking about parallel performance and latency,
so why is ease of use important?

Because the easier a performance technique is to use, the more likely
it will be used.
This greater use can outweigh a small performance penalty compared
to an optimal hard-to-use technique.

This book is not a collection of optimal algorithms with tiny areas of
applicability; instead, it is a handbook of widely applicable and heavily
used techniques.
We of course could not resist the urge to include some of our favorites
that have not (yet!) passed the test of time (what author could?), but
we have nonetheless gritted our teeth and banished our darlings to
appendices.
Perhaps in time, some of them will see enough use that we can promote
them into the main body of the text.

\section{Guide to This Book}
\label{sec:intro:Guide to This Book}

\emph{@@@ More here.  Sections.  Layered Approach.  Appendices.
Quick Quizzes.  Glossary.  Bibliography.}

\subsection{Quick Quizzes}

``Quick quizzes'' appear throughout this book.
Some of these quizzes are based on material in which that quick quiz
appears, but others require you to think beyond that section, and,
in some cases, beyond the entire book.
As with most endeavors, what you get out of this book is largely
determined by what you are willing to put into it.
Therefore, readers who invest some time into these quizzes will
find their effort repaid handsomely with increased understanding
of parallel programming.

Answers to the quizzes may be found in
Appendix~\ref{chp:Answers to Quick Quizzes} starting on
page~\pageref{chp:Answers to Quick Quizzes}.

\emph{@@@ Need some quick quizzes...}
