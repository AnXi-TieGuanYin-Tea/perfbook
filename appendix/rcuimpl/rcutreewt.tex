% appendix/rcuimpl/rcutreewt.tex

% todo...

%DONE% Data structures and module parameters

% External interfaces.
% rcu_check_callbacks, __rcu_process_callbacks, rcu_process_callbacks
%	__call_rcu, call_rcu, call_rcu_bh, __rcu_pending, rcu_pending,
%	rcu_needs_cpu, rcu_cpu_notify, __rcu_init

% initialization, online/offline
% __rcu_offline_cpu, rcu_offline_cpu (empty if !CONFIG_HOTPLUG_CPU)
%	rcu_init_percpu_data, rcu_online_cpu,
%	rcu_init_levelspread (CONFIG_RCU_FANOUT_EXACT and not)
%	rcu_init_one, 

% simple functions: rcu_batches_completed, rcu_batches_completed_bh,
%	cpu_has_callbacks_ready_to_invoke, cpu_needs_another_gp,
%	rcu_get_root,

% rcu_implicit_offline_qs (CONFIG_SMP only)

% rcu_enter_nohz, rcu_exit_nohz, rcu_nmi_enter, rcu_nmi_exit,
%	rcu_irq_enter, rcu_irq_exit -- covered in formal.  Reference.
%	app:formal:Simplicity Avoids Formal Verification
%	Ditto dyntick_save_progress_counter, rcu_implicit_dynticks_qs,
% Cover dyntick_record_completed, dyntick_recall_completed
% Note that dyntick_record_completed() is empty if !CONFIG_NO_HZ.
% Note that dyntick_recall_completed() is subtly different if !CONFIG_NO_HZ.
% Note that dyntick_recall_completed() and rcu_implicit_dynticks_qs are
% 	trivial if !CONFIG_NO_HZ.

% Stall stuff.  record_gp_stall_check_time, print_other_cpu_stall,
%	print_cpu_stall(), check_cpu_stall().
% Note that record_gp_stall_check_time and check_cpu_stall are empty if
%	!CONFIG_RCU_CPU_STALL_DETECTOR

% GP detection.
% note_new_gpnum, check_for_new_grace_period, rcu_start_gp, rcu_process_gp_end,
%	cpu_quiet_msk(), cpu_quiet(), rcu_check_quiescent_state(),
%	rcu_do_batch

\section{Hierarchical RCU Code Walkthrough}
\label{app:rcuimpl:rcutreewt:Hierarchical RCU Code Walkthrough}

This section walks through selected sections of the Linux-kernel
hierarchical RCU code.
As such, this section is intended for hard-core hackers who wish
to understand hierarchical RCU at a very low level.
Hard-core masochists might also be interested in reading this section.

\subsection{Data Structures and Kernel Parameters}
\label{app:rcuimpl:rcutreewt:Data Structures and Kernel Parameters}

@@@ roadmap @@@

\subsubsection{Tracking Dyntick State}
\label{app:rcuimpl:rcutreewt:Tracking Dyntick State}

The per-CPU \url{rcu_dynticks} structure tracks dynticks state using the
following fields:

\begin{description}
\item[\url{dynticks_nesting}:]
	This \url{int} counts the number of reasons that the corresponding
	CPU should be monitored for RCU read-side critical sections.
	If the CPU is in dynticks-idle mode, then this counts the
	irq nesting level, otherwise it is one greater than the
	irq nesting level.
\item[\url{dynticks}:]
	This \url{int} counter's value is even if the corresponding CPU is
	in dynticks-idle mode and there are no irq handlers currently
	running on that CPU, otherwise the counter's value is odd.
	In other words, if this counter's value is odd, then the
	corresponding CPU might be in an RCU read-side critical section.
\item[\url{dynticks_nmi}:]
	This \url{int} counter's value is odd if the corresponding CPU is
	in an NMI handler, but only if the NMI arrived while this
	CPU was in dyntick-idle mode with no irq handlers running.
	Otherwise, the counter's value will be even.
\end{description}

This state is shared between the rcu and rcu\_bh implementations.

\subsubsection{Nodes in the Hierarchy}
\label{app:rcuimpl:rcutreewt:Nodes in the Hierarchy}

As noted earlier, the \url{rcu_node} hierarchy is flattened into
the \url{rcu_state} structure as shown in
Figure~\ref{fig:app:rcuimpl:rcutree:Mapping rcu-node Hierarchy Into Array}
on
page~\pageref{fig:app:rcuimpl:rcutree:Mapping rcu-node Hierarchy Into Array}.
Each \url{rcu_node} in this hierarchy has fields as follows:

\begin{description}
\item[\url{lock}:]
	This spinlock guards the non-constant fields in this structure.
	This lock is acquired from softirq context, so must disable
	irqs.

\QuickQuiz{Why not simply disable bottom halves (softirq) when acquiring
	the \url{rcu_data} structure's \url{lock}?
	Wouldn't this be faster?}
\QuickQuizAnswer{
	Because this lock can be acquired from functions
	called by \url{call_rcu()}, which in turn can be
	invoked from irq handlers.
	Therefore, irqs \emph{must} be disabled when
	holding this lock.
} \QuickQuizEnd

	The \url{lock} field of the root \url{rcu_node} has additional
	responsibilities:
	\begin{enumerate}
	\item	Serializes CPU-stall checking, so that a given stall
		is reported by only one CPU.
		This can be important on systems with thousands of
		CPUs!
	\item	Serializes starting a new grace period, so that
		multiple CPUs don't start conflicting grace periods
		concurrently.
	\item	Prevents new grace periods from starting in code that
		needs to run within the confines of a single grace period.
	\item	Serializes the state machine forcing quiescent states
		(in \url{force_quiescent_state()}) in order to
		keep the number of reschedule IPIs down to a dull
		roar.
	\end{enumerate}
\item[\url{qsmask}:]
	This bitmask tracks which CPUs (for leaf \url{rcu_node} structures)
	or groups of CPUs (for non-leaf \url{rcu_node} structures)
	still need to pass through a quiescent state in order for the
	current grace period to end.
\item[\url{qsmaskinit}:]
	This bitmask tracks which CPUs or groups of CPUs will need to
	pass through a quiescent state for subsequent grace periods
	to end.
	The online/offline code manipulates the \url{qsmaskinit} fields,
	which are copied to the corresponding \url{qsmask} fields at
	the beginning of each grace period.
	This copy operation is one reason why grace period initialization
	must exclude online/offline operations.
\item[\url{grpmask}:]
	This bitmask has a single bit set, and that is the bit corresponding
	to the this \url{rcu_node} structure's position in the parent
	\url{rcu_node} structure's \url{qsmask} and \url{qsmaskinit}
	fields.

\QuickQuiz{How about the \url{qsmask} and \url{qsmaskinit}
	fields for the leaf \url{rcu_node} structures?
	Doesn't there have to be some way to work out
	which of the bits in these fields corresponds
	to each CPU covered by the \url{rcu_node} structure
	in question?}
\QuickQuizAnswer{
	Indeed there does!
	The \url{grpmask} field in each CPU's \url{rcu_data}
	structure does this job.
} \QuickQuizEnd

\item[\url{grplo}:]
	This field contains the number of the lowest-numbered CPU covered
	by this \url{rcu_node} structure.
\item[\url{grphi}:]
	This field contains the number of the highest-numbered CPU covered
	by this \url{rcu_node} structure.
\item[\url{grpnum}:]
	This field contains the bit number in the parent \url{rcu_node}
	structure's \url{qsmask} and \url{qsmaskinit} fields that this
	\url{rcu_node} structure corresponds to.
	In otherwords, given a pointer \url{rnp} to a given
	\url{rcu_node} structure, it will always be the case that
	\url{1UL << rnp->grpnum == rnp->grpmask}.
	The \url{grpnum} field is used only for tracing output.
\item[\url{level}:]
	This field contains zero for the root \url{rcu_node} structure,
	one for the \url{rcu_node} structures that are children of
	the root, and so on down the hierarchy.
\item[\url{parent}:]
	This field is a pointer to the parent \url{rcu_node} structure,
	or NULL for the root \url{rcu_node} structure.
\end{description}

\subsubsection{Per-CPU Data}
\label{app:rcuimpl:rcutreewt:Per-CPU Data}

The \url{rcu_data} structure contains RCU's per-CPU state.
It contains control variables governing grace periods and
quiescent states (\url{completed}, \url{gpnum}, \url{passed_quiesc_completed},
\url{passed_quiesc}, \url{qs_pending}, \url{beenonline}, \url{mynode},
and \url{grpmask}).
The \url{rcu_data} structure also contains control variables pertaining
to RCU callbacks
(\url{nxtlist}, \url{nxttail}, \url{qlen}, and \url{blimit}).
Kernels with dynticks enabled will have relevant control variables in
the \url{rcu_data} structure
(\url{dynticks}, \url{dynticks_snap}, and \url{dynticks_nmi_snap}).
The \url{rcu_data} structure contains event counters used by tracing
(\url{dynticks_fqs} given dynticks, \url{offline_fqs}, and \url{resched_ipi}).
Finally, a pair of fields count calls to \url{rcu_pending()} in order
to determine when to force quiescent states (\url{n_rcu_pending} and
\url{n_rcu_pending_force_qs}), and a \url{cpu} field indicates which
CPU to which a given \url{rcu_data} structure corresponds.

Each of these fields is described below.

\begin{description}
\item[\url{completed}:]
	This field contains the number of the most recent grace period
	that this CPU is aware of having completed.
\item[\url{gpnum}:]
	This field contains the number of the most recent grace period
	that this CPU is aware of having started.
\item[\url{passed_quiesc_completed}:]
	This field contains the number of the grace period that had most
	recently completed when this
	CPU last passed through a quiescent state.
	The "most recently completed" will be from the viewpoint of
	the CPU passing through the quiescent state: if the CPU is
	not yet aware that grace period (say) 42 has completed, it
	will still record the old value of 41.
	This is OK, because the only way that the grace period can
	complete is if this CPU has already passed through a
	quiescent state.
	This field is initialized to a (possibly mythical) past
	grace period number to avoid race conditions when booting
	and when onlining a CPU.
\item[\url{passed_quiesc}:]
	This field indicates whether this CPU has passed
	through a quiescent state since the grace period number
	stored in \url{passed_quiesc_completed} completed.
	This field is cleared each time the corresponding CPU
	becomes aware of the start of a new grace period.
\item[\url{qs_pending}:]
	This field indicates that this CPU is aware that the core
	RCU mechanism is waiting for it to pass through a quiescent state.
	This field is set to one when the CPU detects a new grace
	period or when a CPU is coming online.

\QuickQuiz{But why bother setting \url{qs_pending} to one when a CPU
	is coming online, given that being offline is an extended
	quiescent state that should cover any ongoing grace period?}
\QuickQuizAnswer{
	Because this helps to resolve a race between a CPU coming online
	just as a new grace period is starting.
} \QuickQuizEnd

\QuickQuiz{Why record the last completed grace period number in
	\url{passed_quiesc_completed}?
	Doesn't that cause this RCU implementation to be vulnerable
	to quiescent states seen while no grace period was in progress
	being incorrectly applied to the next grace period that starts?}
\QuickQuizAnswer{
	We record the last completed grace period number in order
	to avoid races where a quiescent state noted near the end of
	one grace period is incorrectly applied to the next grace
	period, especially for dyntick and CPU-offline grace periods.
	Therefore, \url{force_quiescent_state()} and friends all
	check the last completed grace period number to avoid such races.

	Now these dyntick and CPU-offline grace periods are only checked
	for when a grace period is actually active.
	The only quiescent states that can be recorded when no grace
	period is in progress are self-detected quiescent states,
	which are recorded in the \url{passed_quiesc_completed},
	\url{passed_quiesc}, and \url{qs_pending}.
	These variables are initialized every time the corresponding
	CPU notices that a new grace period has started, preventing
	any obsolete quiescent states from being applied to the
	new grace period.

	All that said, optimizing grace-period latency may require that
	\url{gpnum} be tracked in addition to \url{completed}.
} \QuickQuizEnd

\item[\url{beenonline}:]
	This field, initially zero, is set to one whenever the corresponding
	CPU comes online.
	This is used to avoid producing useless tracing output for CPUs
	that never have been online, which is useful in kernels where
	\url{NR_CPUS} greatly exceeds the actual number of CPUs.

\QuickQuiz{What is the point of running a system with \url{NR_CPUS}
	way bigger than the actual number of CPUs?}
\QuickQuizAnswer{
	Because this allows producing a single binary of the Linux kernel
	that runs on a wide variety of systems, greatly easing administration
	and validation.
} \QuickQuizEnd

\item[\url{mynode}:]
	This field is a pointer to the leaf \url{rcu_node} structure that
	handles the corresponding CPU.
\item[\url{grpmask}:]
	This field is a bitmask that has the single bit set that indicates
	which bit in \url{mynode->qsmask} signifies the corresponding CPU.
\item[\url{nxtlist}:]
	This field is a pointer to the oldest RCU callback (\url{rcu_head}
	structure) residing on this CPU, or \url{NULL} if this CPU currently
	has no such callbacks.
	Additional callbacks may be chained via their \url{next} pointers.
\item[\url{nxttail}:]
	This field is an array of double-indirect tail pointers
	into the \url{nxtlist} callback list.
	If \url{nxtlist} is empty, then all of the \url{nxttail} pointers
	directly reference the \url{nxtlist} field.
	Each element of the \url{nxttail} array has meaning as follows:
	\begin{description}
	\item[\url{RCU_DONE_TAIL=0}:]
		This element references the \url{->next} field of
		the last callback that has passed through its grace
		period and is ready to invoke, or references the \url{nxtlist}
		field if there is no such callback.
	\item[\url{RCU_WAIT_TAIL=1}:]
		This element references the \url{next} field of the
		last callback that is waiting for the current grace
		period to end, or is equal to the \url{RCU_DONE_TAIL}
		element if there is no such callback.
	\item[\url{RCU_NEXT_READY_TAIL=2}:]
		This element references the \url{next} field of the
		last callback that is ready to wait for the next
		grace period, or is equal to the \url{RCU_WAIT_TAIL}
		element if there is no such callback.
	\item[\url{RCU_NEXT_TAIL=3}:]
		This element references the \url{next} field of the
		last callback in the list, or references the \url{nxtlist}
		field if the list is empty.
	\end{description}

\QuickQuiz{Why not simply have multiple lists rather than this funny
	multi-tailed list?}
\QuickQuizAnswer{
	Because this multi-tailed approach, due to Lai Jiangshan,
	simplifies callback processing.
} \QuickQuizEnd

\item[\url{qlen}:]
	This field contains the number of callbacks queued on
	\url{nxtlist}.
\item[\url{blimit}:]
	This field contains the maximum number of callbacks that may
	be invoked at a time.
	This limitation improves system responsiveness under heavy load.
\item[\url{dynticks}:]
	This field references the \url{rcu_dynticks} structure for
	the corresponding CPU, which is described in
	Section~\ref{app:rcuimpl:rcutreewt:Tracking Dyntick State}.
\item[\url{dynticks_snap}:]
	This field contains a past value of \url{dynticks->dynticks},
	which is used to detect when a CPU passes through a dynticks
	idle state when this CPU happens to be in an irq
	handler each time that \url{force_quiescent_state()} checks it.
\item[\url{dynticks_nmi_snap}:]
	This field contains a past value of \url{dynticks->dynticks_nmi},
	which is used to detect when a CPU passes through a dynticks
	idle state when this CPU happens to be in an NMI
	handler each time that \url{force_quiescent_state()} checks it.
\item[\url{dynticks_fqs}:]
	This field counts the number of times that some other CPU noted
	a quiescent state on behalf of
	the CPU corresponding to this \url{rcu_data} structure due to
	its being in dynticks-idle mode.
\item[\url{offline_fqs}:]
	This field counts the number of times that some other CPU noted
	a quiescent state on behalf of
	the CPU corresponding to this \url{rcu_data} structure due to
	its being offline.

\QuickQuiz{So some poor CPU has to note quiescent states on behalf of
	each and every offline CPU?
	Yecch!
	Won't that result in excessive overheads in the not-uncommon
	case of a system with a small number of CPUs but a large value
	for \url{NR_CPUS}?}
\QuickQuizAnswer{
	Actually, no it will not!

	Offline CPUs are excluded from both the \url{qsmask} and
	\url{qsmaskinit} bit masks, so RCU normally ignores them.
	However, there are races with online/offline operations that
	can result in an offline CPU having its \url{qsmask} bit set.
	These races must of course be handled correctly, and the way
	they are handled is to permit other CPUs to note that RCU
	is waiting on a quiescent state from an offline CPU.
} \QuickQuizEnd

\item[\url{resched_ipi}:]
	This field counts the number of times that a reschedule IPI
	is sent to the corresponding CPU.
	Such IPIs are sent to CPUs that fail to report passing through
	a quiescent states in a timely manner, but are neither offline
	nor in dynticks idle state.
\item[\url{n_rcu_pending}:]
	This field counts the number of calls to \url{rcu_pending()},
	which is called once per jiffy on non-dynticks-idle CPUs.
\item[\url{n_rcu_pending_force_qs}:]
	This field holds a threshold value for \url{n_rcu_pending}.
	If \url{n_rcu_pending} reaches this threshold, that indicates
	that the current grace period has extended too long, so
	\url{force_quiescent_state()} is invoked to expedite it.
\end{description}

\subsubsection{RCU Global State}
\label{app:rcuimpl:rcutreewt:RCU Global State}

The \url{rcu_state} structure contains RCU's global state for
each instance of RCU (rcu and rcu\_bh).
It includes fields relating to
the hierarchy of \url{rcu_node} structures, including
the \url{node} array itself,
the \url{level} array that contains
pointers to the levels of the hierarchy,
the \url{levelcnt} array that contains the count of nodes at each level
of the hierarchy,
the \url{levelspread} array that contains the number of children
per node for each level of the hierarchy,
and the \url{rda} array of pointer to each of the CPU's
\url{rcu_data} structures.
The \url{rcu_state} structure also contains a number of fields
coordinating various details of the current grace period and its
interaction with other mechanisms (\url{signaled},
\url{gpnum}, \url{completed}, \url{onofflock}, \url{fqslock},
\url{jiffies_force_qs}, \url{n_force_qs}, \url{n_force_qs_lh},
\url{n_force_qs_ngp}, \url{gp_start}, \url{jiffies_stall},
and \url{dynticks_completed}).

Each of these fields are described below.

\begin{description}
\item[\url{node}:]
	This field is the array of \url{rcu_node} structures,
	with the root node of the hierarchy being located at
	\url{->node[0]}.
	The size of this array is specified by the
	\url{NUM_RCU_NODES} C-preprocessor macro, which is computed
	from \url{NR_CPUS} and \url{CONFIG_RCU_FANOUT}
	as described in
	Section~\ref{app:rcuimpl:rcutreewt:Kernel Parameters}.
	Note that traversing the \url{->node} array starting at
	element zero has the effect of doing a breadth-first search
	of the \url{rcu_node} hierarchy.
\item[\url{level}:]
	This field is an array of pointers into the \url{node} array.
	The root node of the hierarchy is referenced by
	\url{->level[0]}, the first node of the second level of
	the hierarchy (if there is one) by \url{->level[1]}, and so on.
	The first leaf node is referenced by
	\url{->level[NUM_RCU_LVLS-1]}, and the size of the \url{level}
	array is thus specified by \url{NUM_RCU_LVLS}, which is
	computed as described in
	Section~\ref{app:rcuimpl:rcutreewt:Kernel Parameters}.
	The \url{->level} field is often used in combination with 
	\url{->node} to scan a level of the \url{rcu_node} hierarchy,
	for example, all of the leaf nodes.
	The elements of \url{->level} are filled in by the
	boot-time \url{rcu_init_one()} function.
\item[\url{levelcnt}:]
	This field is an array containing the number of \url{rcu_node}
	structures in each level of the hierarchy, including the
	number of \url{rcu_data} structures referencing the leaf
	\url{rcu_node} structures, so that this array has one more
	element than does the \url{->level} array.
	Note that \url{->levelcnt[0]} will always contain a value of
	one, corresponding to the single root \url{rcu_node} at the
	top of the hierarchy.
	This array is initialized with the values
	\url{NUM_RCU_LVL_0},
	\url{NUM_RCU_LVL_1},
	\url{NUM_RCU_LVL_2}, and
	\url{NUM_RCU_LVL_3},
	which are C-preprocessor macros computed as described in
	Section~\ref{app:rcuimpl:rcutreewt:Kernel Parameters}.
	The \url{->levelcnt} field is used to initialize
	other parts of the hierarchy and for debugging purposes.
\item[\url{levelspread}:]
	Each element of this field contains the desired number of children
	for the corresponding level of the \url{rcu_node} hierarchy.
	This array's element's values are computed at runtime
	by one of the two \url{rcu_init_levelspread()} functions,
	selected by the \url{CONFIG_RCU_FANOUT_EXACT} kernel parameter.
\item[\url{rda}:]
	Each element of this field contains a pointer to the
	corresponding CPU's \url{rcu_data} structure.
	This array is initialized at boot time by the
	\url{RCU_DATA_PTR_INIT()} macro.
\item[\url{signaled}:]
	This field is used to maintain state used by the
	\url{force_quiescent_state()} function, as described in
	Section~\ref{app:rcuimpl:rcutreewt:Forcing Quiescent States}.
	This field takes on values as follows:
	\begin{description}
	\item[\url{RCU_GP_INIT}:]
		This value indicates that the current grace period
		is still in the process of being initialized,
		so that \url{force_quiescent_state()} should take
		no action.
		Of course, grace-period initialization would need
		to stretch out for three jiffies before this race
		could arise, but if you have a very large number
		of CPUs, this race could in fact occur.
		Once grace-period initialization is complete,
		this value is set to either \url{RCU_SAVE_DYNTICK}
		(if \url{CONFIG_NO_HZ}) or \url{RCU_FORCE_QS} otherwise.
	\item[\url{RCU_SAVE_DYNTICK}:]
		This value indicates that \url{force_quiescent_state()}
		should check the dynticks state of any CPUs that have
		not yet reported quiescent states for the current
		grace period.
		Quiescent states will be reported on behalf of any
		CPUs that are in dyntick-idle mode.
	\item[\url{RCU_FORCE_QS}:]
		This value indicates that \url{force_quiescent_state()}
		should recheck dynticks state along with the online/offline
		state of any CPUs that have
		not yet reported quiescent states for the current
		grace period.
		The rechecking of dynticks states allows the implementation
		to handle cases where a given CPU might be in dynticks-idle
		state, but have been in an irq or NMI handler both
		times it was checked.
		If all else fails, a reschedule IPI will be sent to
		the laggart CPU.
	\end{description}
	This field is guarded by the root \url{rcu_node} structure's lock.

\QuickQuiz{So what guards the earlier fields in this structure?}
\QuickQuizAnswer{
	Nothing does, as they are constants set at compile time
	or boot time.
	Of course, the fields internal to each \url{rcu_node}
	in the \url{->node} array may change, but they are
	guarded separately.
} \QuickQuizEnd

\item[\url{gpnum}:]
	This field contains the number of the current grace period,
	or that of the last grace period if no grace period is currently
	in effect.
	This field is guarded by the root \url{rcu_node} structure's lock,
	but is frequently accessed (but never modified) without holding
	this lock.
\item[\url{completed}:]
	This field contains the number of the last completed grace period.
	As such, it is equal to \url{->gpnum} when there is no grace period
	in progress, or one less than \url{->gpnum} when there is a
	grace period in progress.
	In principle, one could replace this pair of fields with a single
	boolean, as is done in Classic RCU in some versions of Linux,
	but in practice race resolution is much simpler given the pair
	of numbers.
	This field is guarded by the root \url{rcu_node} structure's lock,
	but is frequently accessed (but never modified) without holding
	this lock.
\item[\url{onofflock}:]
	This field prevents online/offline processing from running
	concurrently with grace-period initialization.
	There is one exception to this: if the \url{rcu_node}
	hierarchy consists of but a single structure, then
	that single structure's \url{->lock} field will instead take on
	this job.
\item[\url{fqslock}:]
	This field prevents more than one task from forcing quiescent
	states with \url{force_quiescent_state()}.
\item[\url{jiffies_force_qs}:]
	This field contains the time, in jiffies, when
	\url{force_quiescent_state()} should be invoked in order to
	force CPUs into quiescent states and/or report extended
	quiescent states.
	This field is guarded by the root \url{rcu_node} structure's lock,
	but is frequently accessed (but never modified) without holding
	this lock.
\item[\url{n_force_qs}:]
	This field counts the number of calls to \url{force_quiescent_state()}
	that actually do work, as opposed to leaving early due to
	the grace period having already completed, some other
	CPU currently running \url{force_quiescent_state()},
	or \url{force_quiescent_state()} having run too recently.
	This field is used for tracing and debugging, and
	is guarded by \url{->fqslock}.
\item[\url{n_force_qs_lh}:]
	This field holds an approximate count of the number of times that
	\url{force_quiescent_state()} returned early due to the
	\url{->fqslock} being held by some other CPU.
	This field is used for tracing and debugging, and is not
	guarded by any lock, hence its approximate nature.
\item[\url{n_force_qs_ngp}:]
	This field counts the number of times that
	\url{force_quiescent_state()} that successfully acquire
	\url{->fqslock}, but then find that there is no grace period
	in progress.
	This field is used for tracing and debugging, and
	is guarded by \url{->fqslock}.
\item[\url{gp_start}:]
	This field records the time at which the most recent grace period
	began, in jiffies.
	This is used to detect stalled CPUs, but only when the
	\url{CONFIG_RCU_CPU_STALL_DETECTOR} kernel parameter is selected.
	This field is guarded by the root \url{rcu_node}'s \url{->lock},
	but is sometimes accessed (but not modified) outside of this
	lock.
\item[\url{jiffies_stall}:]
	This field holds the time, in jiffies, at which the current
	grace period will have extended for so long that it will
	be appropriate to check for CPU stalls.
	As with \url{->gp_start}, this field exists only when the
	\url{CONFIG_RCU_CPU_STALL_DETECTOR} kernel parameter is selected.
	This field is guarded by the root \url{rcu_node}'s \url{->lock},
	but is sometimes accessed (but not modified) outside of this
	lock.
\item[\url{dynticks_completed}:]
	This field records the value of \url{->completed} at the time when
	\url{force_quiescent_state()} snapshots dyntick state, but
	is also initialized to an earlier grace period at the beginning
	of each grace period.
	This field is used to prevent dyntick-idle quiescent states
	from a prior grace period from being applied to the current
	grace period.
	As such, this field exists only when the \url{CONFIG_NO_HZ}
	kernel parameter is selected.
	This field is guarded by the root \url{rcu_node}'s \url{->lock},
	but is sometimes accessed (but not modified) outside of this
	lock.
\end{description}

\subsubsection{Kernel Parameters}
\label{app:rcuimpl:rcutreewt:Kernel Parameters}

The following kernel parameters affect this variant of RCU:

\begin{itemize}
\item	\url{NR_CPUS}, the maximum number of CPUs in the system.
\item	\url{CONFIG_RCU_FANOUT}, the desired number of children for
	each node in the \url{rcu_node} hierarchy.
\item	\url{CONFIG_RCU_FANOUT_EXACT}, a boolean preventing rebalancing
	of the \url{rcu_node} hierarchy.
\item	\url{CONFIG_HOTPLUG_CPU}, permitting CPUs to come online and go
	offline.
\item	\url{CONFIG_NO_HZ}, indicating that dynticks-idle mode is supported.
\item	\url{CONFIG_SMP}, indicating that multiple CPUs may be present.
\item	\url{CONFIG_RCU_CPU_STALL_DETECTOR}, indicating that RCU should
	check for stalled CPUs when RCU grace periods extend too long.
\item	\url{CONFIG_RCU_TRACE}, indicating that RCU should provide
	tracing information in \url{debugfs}.
\end{itemize}

\begin{figure*}[htbp]
{
\begin{verbatim}
  1 #define MAX_RCU_LVLS    3
  2 #define RCU_FANOUT      (CONFIG_RCU_FANOUT)
  3 #define RCU_FANOUT_SQ   (RCU_FANOUT * RCU_FANOUT)
  4 #define RCU_FANOUT_CUBE (RCU_FANOUT_SQ * RCU_FANOUT)
  5 
  6 #if NR_CPUS <= RCU_FANOUT
  7 #  define NUM_RCU_LVLS  1
  8 #  define NUM_RCU_LVL_0 1
  9 #  define NUM_RCU_LVL_1 (NR_CPUS)
 10 #  define NUM_RCU_LVL_2 0
 11 #  define NUM_RCU_LVL_3 0
 12 #elif NR_CPUS <= RCU_FANOUT_SQ
 13 #  define NUM_RCU_LVLS  2
 14 #  define NUM_RCU_LVL_0 1
 15 #  define NUM_RCU_LVL_1 (((NR_CPUS) + RCU_FANOUT - 1) / RCU_FANOUT)
 16 #  define NUM_RCU_LVL_2 (NR_CPUS)
 17 #  define NUM_RCU_LVL_3 0
 18 #elif NR_CPUS <= RCU_FANOUT_CUBE
 19 #  define NUM_RCU_LVLS  3
 20 #  define NUM_RCU_LVL_0 1
 21 #  define NUM_RCU_LVL_1 (((NR_CPUS) + RCU_FANOUT_SQ - 1) / RCU_FANOUT_SQ)
 22 #  define NUM_RCU_LVL_2 (((NR_CPUS) + (RCU_FANOUT) - 1) / (RCU_FANOUT))
 23 #  define NUM_RCU_LVL_3 NR_CPUS
 24 #else
 25 # error "CONFIG_RCU_FANOUT insufficient for NR_CPUS"
 26 #endif /* #if (NR_CPUS) <= RCU_FANOUT */
 27 
 28 #define RCU_SUM (NUM_RCU_LVL_0 + NUM_RCU_LVL_1 + NUM_RCU_LVL_2 + NUM_RCU_LVL_3)
 29 #define NUM_RCU_NODES (RCU_SUM - NR_CPUS)
\end{verbatim}
}
\caption{Determining Shape of RCU Hierarchy}
\label{fig:app:rcuimpl:rcutreewt:Determining Shape of RCU Hierarchy}
\end{figure*}

The \url{CONFIG_RCU_FANOUT} and \url{NR_CPUS} parameters are used to
determine the shape of the \url{rcu_node} hierarchy at compile time,
as shown in
Figure~\ref{fig:app:rcuimpl:rcutreewt:Determining Shape of RCU Hierarchy}.
Line~1 defines the maximum depth of the \url{rcu_node} hierarchy,
currently three.
Note that increasing the maximum permitted depth requires changes
elsewhere, for example, adding another leg to the \url{#if}
statement running from lines~6-26.
Lines~2-4 compute the fanout, the square of the fanout, and the cube
of the fanout, respectively.

Then these values are compared to \url{NR_CPUS} to determine the required
depth of the \url{rcu_node} hierarchy, which is placed into
\url{NUM_RCU_LVLS}, which is used to size a number of arrays
in the \url{rcu_state} structure.
There is always one node at the root level, and there are always
\url{NUM_CPUS} number of \url{rcu_data} structures below the leaf
level.
If there is more than just the root level, the number of nodes at
the leaf level is computed
by dividing \url{NR_CPUS} by \url{RCU_FANOUT}, rounding up.
The number of nodes at other levels is computed in a similar manner,
but using (for example) \url{RCU_FANOUT_SQ} instead of \url{RCU_FANOUT}.

Line~28 then sums up all of the levels, resulting in the number of
\url{rcu_node} structures plus the number of \url{rcu_data} structures.
Finally, line~29 subtracts \url{NR_CPUS} (which is the number of
\url{rcu_data} structures) from the sum, resulting in the number
of \url{rcu_node} structures, which is retained in
\url{NUM_RCU_NODES}.
This value is then used to size the \url{->nodes} array in the
\url{rcu_state} structure.

\subsection{External Interfaces}
\label{app:rcuimpl:rcutreewt:External Interfaces}

RCU's external interfaces include not just the standard RCU API,
but also the internal interfaces to the rest of the kernel that
are required for the RCU implementation itself.
The interfaces are
\url{call_rcu()} (which is a wrapper around
\url{__call_rcu()}),
\url{call_rcu_bh()} (ditto),
\url{rcu_check_callbacks()},
\url{rcu_process_callbacks()} (which is a wrapper around
\url{__rcu_process_callbacks()},
\url{rcu_pending()} (which is a wrapper around
\url{__rcu_pending()}),
\url{rcu_needs_cpu()},
\url{rcu_cpu_notify()}, and
\url{__rcu_init()}.
Note that \url{synchronize_rcu()} and \url{rcu_barrier()} are
common to all RCU implementations, and are defined in terms of
\url{call_rcu()}.
Similarly, \url{rcu_barrier_bh()} is common to all RCU implementations
and is defined in terms of \url{call_rcu_bh()}.

\subsubsection{\tt call\_rcu()}
\label{app:rcuimpl:rcutreewt:call-rcu}

\begin{figure}[htbp]
{ \scriptsize
\begin{verbatim}
  1 static void
  2 __call_rcu(struct rcu_head *head,
  3            void (*func)(struct rcu_head *rcu),
  4            struct rcu_state *rsp)
  5 {
  6   unsigned long flags;
  7   struct rcu_data *rdp;
  8 
  9   head->func = func;
 10   head->next = NULL;
 11   smp_mb();
 12   local_irq_save(flags);
 13   rdp = rsp->rda[smp_processor_id()];
 14   rcu_process_gp_end(rsp, rdp);
 15   check_for_new_grace_period(rsp, rdp);
 16   *rdp->nxttail[RCU_NEXT_TAIL] = head;
 17   rdp->nxttail[RCU_NEXT_TAIL] = &head->next;
 18   if (ACCESS_ONCE(rsp->completed) ==
 19       ACCESS_ONCE(rsp->gpnum)) {
 20     unsigned long nestflag;
 21     struct rcu_node *rnp_root = rcu_get_root(rsp);
 22 
 23     spin_lock_irqsave(&rnp_root->lock, nestflag);
 24     rcu_start_gp(rsp, nestflag);
 25   }
 26   if (unlikely(++rdp->qlen > qhimark)) {
 27     rdp->blimit = LONG_MAX;
 28     force_quiescent_state(rsp, 0);
 29   } else if ((long)(ACCESS_ONCE(rsp->jiffies_force_qs) -
 30                     jiffies) < 0 ||
 31              (rdp->n_rcu_pending_force_qs -
 32               rdp->n_rcu_pending) < 0)
 33     force_quiescent_state(rsp, 1);
 34   local_irq_restore(flags);
 35 }
 36 
 37 void call_rcu(struct rcu_head *head,
 38               void (*func)(struct rcu_head *rcu))
 39 {
 40   __call_rcu(head, func, &rcu_state);
 41 }
 42 
 43 void call_rcu_bh(struct rcu_head *head,
 44                  void (*func)(struct rcu_head *rcu))
 45 {
 46   __call_rcu(head, func, &rcu_bh_state);
 47 }
\end{verbatim}
}
\caption{{\tt call\_rcu()} Code}
\label{fig:app:rcuimpl:rcutreewt:Code for rcutree call-rcu}
\end{figure}

Figure~\ref{fig:app:rcuimpl:rcutreewt:Code for rcutree call-rcu}
shows the code for \url{__call_rcu()}, \url{call_rcu()}, and
\url{call_rcu_bh()}.
Note that \url{call_rcu()} and \url{call_rcu_bh()} are simple wrappers
for \url{call_rcu()}, and thus will not be considered further here.

Turning attention to \url{__call_rcu()}, lines~9-10 initialize the
specified \url{rcu_head}, and line~11 ensures that updates to
RCU-protected data structures carried out prior to invoking
\url{__call_rcu()} are seen prior to callback registry.
Lines~12 and 34 disable and re-enable interrupts to prevent destructive
interference by any calls to \url{__call_rcu()} from an interrupt
handler.
Line 13 obtains a reference to the current CPU's \url{rcu_data}
structure, line~14 invokes \url{rcu_process_gp_end()} in order
to advance callbacks if the current grace period has now ended,
while line~15 invokes \url{check_for_new_grace_period()} to
record state if a new grace period has started.

\QuickQuiz{Why not simply use \url{__get_cpu_var()} to pick up a
	reference to the
	current CPU's \url{rcu_data} structure on line~13 in
	Figure~\ref{fig:app:rcuimpl:rcutreewt:Code for rcutree call-rcu}?}
\QuickQuizAnswer{
	Because we might be called either from \url{call_rcu()}
	(in which case we would need \url{__get_cpu_var(rcu_data)})
	or from \url{call_rcu_bh()} (in which case we would need
	\url{__get_cpu_var(rcu_bh_data)}).
	Using the \url{->rda[]} array of whichever
	\url{rcu_state} structure we were passed works correctly
	regardless of which API \url{__call_rcu()} was invoked from
	(suggested by Lai Jiangshan).
} \QuickQuizEnd

Lines~16 and 17 enqueue the new callback.
Lines 18 and 19 check to see there is a grace period in progress,
and, if not, line~23 acquires the root \url{rcu_node} structure's
lock and line~24 invokes \url{rcu_start_gp()} to start a new grace
period (and also to release the lock).

Line~26 checks to see if too many RCU callbacks are waiting on
this CPU, and, if so, line~27 increases \url{->blimit} in order
to increase the rate at which callbacks are processed, while
line~28 invokes \url{force_quiescent_state()} urgently in order to
try to convince holdout CPUs to pass through quiescent states.
Otherwise, lines~29-32 check to see if it has been too long since
the grace period started (or since the last call to
\url{force_quiescent_state()}, as the case may be), and, if so,
line~33 invokes \url{force_quiescent_state()} non-urgently, again
to convince holdout CPUs to pass through quiescent states.

\subsubsection{\tt rcu\_check\_callbacks()}
\label{app:rcuimpl:rcutreewt:rcu-check-callbacks}

\begin{figure}[htbp]
{ \scriptsize
\begin{verbatim}
  1 static int __rcu_pending(struct rcu_state *rsp,
  2                          struct rcu_data *rdp)
  3 {
  4   rdp->n_rcu_pending++;
  5 
  6   check_cpu_stall(rsp, rdp);
  7   if (rdp->qs_pending)
  8     return 1;
  9   if (cpu_has_callbacks_ready_to_invoke(rdp))
 10     return 1;
 11   if (cpu_needs_another_gp(rsp, rdp))
 12     return 1;
 13   if (ACCESS_ONCE(rsp->completed) != rdp->completed)
 14     return 1;
 15   if (ACCESS_ONCE(rsp->gpnum) != rdp->gpnum)
 16     return 1;
 17   if (ACCESS_ONCE(rsp->completed) !=
 18       ACCESS_ONCE(rsp->gpnum) &&
 19       ((long)(ACCESS_ONCE(rsp->jiffies_force_qs) -
 20               jiffies) < 0 ||
 21        (rdp->n_rcu_pending_force_qs -
 22         rdp->n_rcu_pending) < 0))
 23     return 1;
 24   return 0;
 25 }
 26 
 27 int rcu_pending(int cpu)
 28 {
 29   return __rcu_pending(&rcu_state,
 30                        &per_cpu(rcu_data, cpu)) ||
 31          __rcu_pending(&rcu_bh_state,
 32                        &per_cpu(rcu_bh_data, cpu));
 33 }
 34 
 35 void rcu_check_callbacks(int cpu, int user)
 36 {
 37   if (user ||
 38       (idle_cpu(cpu) && !in_softirq() &&
 39        hardirq_count() <= (1 << HARDIRQ_SHIFT))) {
 40     smp_mb();
 41     rcu_qsctr_inc(cpu);
 42     rcu_bh_qsctr_inc(cpu);
 43   } else if (!in_softirq()) {
 44     smp_mb();
 45     rcu_bh_qsctr_inc(cpu);
 46   }
 47   raise_softirq(RCU_SOFTIRQ);
 48 }
\end{verbatim}
}
\caption{{\tt rcu\_check\_callbacks()} Code}
\label{fig:app:rcuimpl:rcutreewt:Code for rcutree rcu-check-callbacks}
\end{figure}

Figure~\ref{fig:app:rcuimpl:rcutreewt:Code for rcutree rcu-check-callbacks}
shows the code that is called from the scheduling-clock interrupt
handler once per jiffy from each CPU.
The \url{rcu_pending()} function (which is a wrapper for \url{__rcu_pending()})
is invoked, and if it returns non-zero, then \url{rcu_check_callbacks()}
is invoked.
(Note that there is some thought being given to merging \url{rcu_pending()}
into \url{rcu_check_callbacks()}.)

Starting with \url{__rcu_pending()}, line 4 counts this call to
\url{rcu_pending()} for use in deciding when to force quiescent states.
Line~6 invokes \url{check_cpu_stall()} in order to report on CPUs
that are spinning in the kernel, or perhaps that have hardware problems,
if \url{CONFIG_RCU_CPU_STALL_DETECTOR} is selected.
Lines~7-23 perform a series of checks, returning non-zero if RCU
needs the current CPU to do something.
Line~7 checks to see if the current CPU owes RCU a quiescent state for the
current grace period,
line~9 invokes \url{cpu_has_callbacks_ready_to_invoke()} to see if
the current CPU has callbacks whose grace period has ended, thus being
ready to invoke,
line~11 invokes \url{cpu_needs_another_gp()} to see if the current
CPU has callbacks that need another RCU grace period to elapse,
line~13 checks to see if the current grace period has ended,
line~15 checks to see if a new grace period has started,
and, finally, lines 17-22 check to see if it is time to attempt
to force holdout CPUs to pass through a quiescent state.
This latter check breaks down as follows: (1) lines~17-18 check to see
if there is a grace period in progress, and, if so, lines~19-22
check to see if sufficient jiffies (lines~19-20) or calls to
\url{rcu_pending()} (lines~21-22) have elapsed that
\url{force_quiescent_state()} should be invoked.
If none of the checks in the series triggers, then line~24 returns
zero, indicating that \url{rcu_check_callbacks()} need not be invoked.

Lines~27-33 show \url{rcu_pending()}, which simply invokes
\url{__rcu_pending()} twice, once for ``rcu'' and again for
``rcu\_bh''.

\QuickQuiz{Given that \url{rcu_pending()} is always called twice
	on lines~29-32 of
	Figure~\ref{fig:app:rcuimpl:rcutreewt:Code for rcutree rcu-check-callbacks},
	shouldn't there be some way to combine the checks of the
	two structures?}
\QuickQuizAnswer{
	Sorry, but this was a trick question.
	The C language's short-circuit boolean expression evaluation
	means that \url{__rcu_pending()} is invoked on
	\url{rcu_bh_state} only if the prior invocation on
	\url{rcu_state} returns zero.

	The reason the two calls are in this order is that
	``rcu'' is used more heavily than is ``rcu\_bh'', so
	the first call is more likely to return non-zero than
	is the second.
} \QuickQuizEnd

Lines~35-48 show \url{rcu_check_callbacks()}, which checks to see
if the scheduling-clock interrupt interrupted an extended quiescent
state, and then initiates RCU's softirq processing
(\url{rcu_process_callbacks()}).
Lines~37-42 perform this check for ``rcu'', while lines~43-45
perform the check for ``rcu\_bh''.

Lines~37-39 check to see if the scheduling clock interrupt came
from user-mode execution (line~37) or directly from the idle
loop (line~38's \url{idle_cpu()} invocation) with no intervening
levels of interrupt (the remainder of line~38 and all of line~39).
If this check succeeds, so that the scheduling clock interrupt
did come from an extended quiescent state,
line~40 executes a memory barrier to ensure that any prior
RCU read-side critical sections are seen prior to any subsequent
grace-period processing on this CPU.
Because any quiescent state for ``rcu'' is also a quiescent state
for ``rcu\_bh'', lines~41 and 42 report the quiescent state for
both flavors of RCU.

Similarly for ``rcu\_bh'', line~43 checks to see if the scheduling-clock
interrupt came from a region of code with softirqs enabled, and, if so
line~44 executes a memory barrier and line~45 reports the quiescent
state for ``rcu\_bh'' only.

\QuickQuiz{Shouldn't line~43 of
	Figure~\ref{fig:app:rcuimpl:rcutreewt:Code for rcutree rcu-check-callbacks}
	also check for \url{in_hardirq()}?}
\QuickQuizAnswer{
	No.
	The \url{rcu_read_lock_bh()} primitive disables
	softirq, not hardirq.
	Because \url{call_rcu_bh()} need only wait for pre-existing
	``rcu\_bh'' read-side critical sections to complete,
	we need only check \url{in_softirq()}.
} \QuickQuizEnd

In either case, line~47 invokes an RCU softirq, which will result in
\url{rcu_process_callbacks()} being called on this CPU at some future
time (like when interrupts are re-enabled after exiting the
scheduler-clock interrupt).

\subsubsection{\tt rcu\_process\_callbacks()}
\label{app:rcuimpl:rcutreewt:rcu-process-callbacks}

\begin{figure}[htbp]
{ \scriptsize
\begin{verbatim}
  1 static void
  2 __rcu_process_callbacks(struct rcu_state *rsp,
  3                         struct rcu_data *rdp)
  4 {
  5   unsigned long flags;
  6 
  7   if ((long)(ACCESS_ONCE(rsp->jiffies_force_qs) -
  8              jiffies) < 0 ||
  9       (rdp->n_rcu_pending_force_qs -
 10        rdp->n_rcu_pending) < 0)
 11     force_quiescent_state(rsp, 1);
 12   rcu_process_gp_end(rsp, rdp);
 13   rcu_check_quiescent_state(rsp, rdp);
 14   if (cpu_needs_another_gp(rsp, rdp)) {
 15     spin_lock_irqsave(&rcu_get_root(rsp)->lock, flags);
 16     rcu_start_gp(rsp, flags);
 17   }
 18   rcu_do_batch(rdp);
 19 }
 20 
 21 static void
 22 rcu_process_callbacks(struct softirq_action *unused)
 23 {
 24   smp_mb();
 25   __rcu_process_callbacks(&rcu_state,
 26                           &__get_cpu_var(rcu_data));
 27   __rcu_process_callbacks(&rcu_bh_state,
 28                           &__get_cpu_var(rcu_bh_data));
 29   smp_mb();
 30 }
\end{verbatim}
}
\caption{{\tt rcu\_process\_callbacks()} Code}
\label{fig:app:rcuimpl:rcutreewt:Code for rcutree rcu-process-callbacks}
\end{figure}

Figure~\ref{fig:app:rcuimpl:rcutreewt:Code for rcutree rcu-process-callbacks}
@@@

% \url{rcu_needs_cpu()},
% \url{rcu_cpu_notify()}, and
% \url{__rcu_init()}.

\subsection{Forcing Quiescent States}
\label{app:rcuimpl:rcutreewt:Forcing Quiescent States}

Normally, CPUs pass through quiescent states which are duly recorded,
so that grace periods end in a timely manner.
However, any of the following three conditions can prevent CPUs from
passing through quiescent states:

\begin{enumerate}
\item	The CPU is in dyntick-idle state, and is sleeping in a low-power
	mode.
	Although such a CPU is officially in an extended quiescent state,
	because it is not executing instructions, it cannot do anything
	on its own.
\item	The CPU is in the process of coming online, and RCU has been
	informed that it is online, but this CPU is not yet actually
	executing code, nor is it marked as online in \url{cpu_online_map}.
	The current grace period will therefore wait on it, but it cannot
	yet pass through quiescent states on its own.
\item	The CPU is running user-level code, but has avoided
	entering the scheduler for an extended time period.
\end{enumerate}

In each of these cases, RCU needs to take action on behalf of the
non-responding CPU.
This section describes the functions that take such action.

% rcu_process_dyntick

% @@@ the code in the following figure needs to be redone: recently changed.

\begin{figure}[htbp]
{ \scriptsize
\begin{verbatim}
  1 static void
  2 force_quiescent_state(struct rcu_state *rsp, int relaxed)
  3 {
  4   unsigned long flags;
  5   long lastcomp;
  6   struct rcu_data *rdp = rsp->rda[smp_processor_id()];
  7   struct rcu_node *rnp = rcu_get_root(rsp);
  8   u8 signaled;
  9 
 10   if (ACCESS_ONCE(rsp->completed) ==
 11       ACCESS_ONCE(rsp->gpnum))
 12     return;
 13   if (!spin_trylock_irqsave(&rsp->fqslock, flags)) {
 14     rsp->n_force_qs_lh++;
 15     return;
 16   }
 17   if (relaxed &&
 18       (long)(rsp->jiffies_force_qs - jiffies) >= 0 &&
 19       (rdp->n_rcu_pending_force_qs -
 20        rdp->n_rcu_pending) >= 0)
 21     goto unlock_ret;
 22   rsp->n_force_qs++;
 23   spin_lock(&rnp->lock);
 24   lastcomp = rsp->completed;
 25   signaled = rsp->signaled;
 26   rsp->jiffies_force_qs =
 27     jiffies + RCU_JIFFIES_TILL_FORCE_QS;
 28   rdp->n_rcu_pending_force_qs =
 29     rdp->n_rcu_pending +
 30     RCU_JIFFIES_TILL_FORCE_QS;
 31   if (lastcomp == rsp->gpnum) {
 32     rsp->n_force_qs_ngp++;
 33     spin_unlock(&rnp->lock);
 34     goto unlock_ret;
 35   }
 36   spin_unlock(&rnp->lock);
 37   switch (signaled) {
 38   case RCU_GP_INIT:
 39     break;
 40   case RCU_SAVE_DYNTICK:
 41     if (RCU_SIGNAL_INIT != RCU_SAVE_DYNTICK)
 42       break;
 43     if (rcu_process_dyntick(rsp, lastcomp,
 44           dyntick_save_progress_counter))
 45       goto unlock_ret;
 46     spin_lock(&rnp->lock);
 47     if (lastcomp == rsp->completed) {
 48       rsp->signaled = RCU_FORCE_QS;
 49       dyntick_record_completed(rsp, lastcomp);
 50     }
 51     spin_unlock(&rnp->lock);
 52     break;
 53   case RCU_FORCE_QS:
 54     if (rcu_process_dyntick(rsp,
 55           dyntick_recall_completed(rsp),
 56           rcu_implicit_dynticks_qs))
 57       goto unlock_ret;
 58     break;
 59   }
 60 unlock_ret:
 61   spin_unlock_irqrestore(&rsp->fqslock, flags);
 62 }
\end{verbatim}
}
\caption{{\tt force\_quiescent\_state()} Code}
\label{fig:app:rcuimpl:rcutreewt:Code for rcutree force-quiescent-state}
\end{figure}

Figure~\ref{fig:app:rcuimpl:rcutreewt:Code for rcutree force-quiescent-state}
shows the code for \url{force_quiescent_state()} for
\url{CONFIG_SMP},\footnote{
	For non-\url{CONFIG_SMP}, \url{force_quiescent_state} is a
	simple wrapper around \url{set_need_resched()}.}
which is invoked when RCU feels the need to expedite the current
grace period by forcing CPUs through quiescent states.
RCU feels this need when either:
\begin{enumerate}
\item	the current grace period has gone on for more than three jiffies
	(or as specified by the compile-time value of
	\url{RCU_JIFFIES_TILL_FORCE_QS}), or
\item	a CPU enqueuing an RCU callback via either \url{call_rcu()}
	or \url{call_rcu_bh()} sees more than 10,000 callbacks enqueued
	(or as specified by the boot-time parameter \url{qhimark}).
\end{enumerate}

Lines~10-12 check to see if there is a grace period in progress,
silently exiting if not.
Lines~13-16 attempt to acquire \url{->fqslock}, which prevents concurrent
attempts to expedite a grace period.
The \url{->n_force_qs_lh} counter is incremented when this lock is
already held, and is visible via the \url{fqlh=} field
in the \url{rcuhier} debugfs file when the \url{CONFIG_RCU_TRACE} kernel
parameter is enabled.
Lines~17-21 check to see if it is really necessary to expedite the
current grace period, in other words, if (1) the current CPU has 10,000
RCU callbacks waiting, or (2) at least three jiffies have passed
since either the beginning of the current grace period or since the
last attempt to expedite the current grace period, measured either
by the \url{jiffies} counter or by the number of calls to
\url{rcu_pending}.
Line~22 then counts the number of attempts to expedite grace periods.

Lines~23-36 are executed with the root \url{rcu_node} structure's lock
held in order to prevent confusion should the current grace period
happen to end just as we try to expedite it.
Lines~24 and 25 snapshot the \url{->completed} and \url{\signaled} fields,
lines~26-30 set the soonest time that a subsequent non-relaxed
\url{force_quiescent_state()} will be allowed to actually do
any expediting, and lines~31-35 check to see if the grace period
ended while we were acquiring the \url{rcu_node} structure's lock,
releasing this lock and returning if so.

Lines~37-59 drive the \url{force_quiescent_state()} state machine.
If the grace period is still in the midst of initialization,
lines~41 and 42 simply return, allowing \url{force_quiescent_state()}
to be called again at a later time, presumably after initialization
has completed.
If dynticks are enabled (via the \url{CONFIG_NO_HZ} kernel
parameter), the first post-initialization call
to \url{force_quiescent_state()} in a given grace period will
execute lines~40-52, and the second and subsequent calls will
execute lines~53-59.
On the other hand, if dynticks is not enabled, then all post-initialization
calls to \url{force_quiescent_state()} will execute lines~53-59.

The purpose of lines~40-52 is to record the current dynticks-idle state
of all CPUs that have not yet passed through a quiescent state, and
to record a quiescent state for any that are currently in dynticks-idle
state (but not currently in an irq or NMI handler).
Lines~41-42 serve to inform gcc that this branch of the switch statement
is dead code for non-\url{CONFIG_NO_HZ} kernels.
Lines 43-45 invoke \url{rcu_process_dyntick()} in order to invoke
\url{dyntick_save_progress_counter()} for each CPU that has not yet
passed through a quiescent state for the current grace period,
exiting \url{force_quiescent_state()} if the grace period ends in
the meantime (possibly due to having found that all the CPUs that
had not yet passed through a quiescent state were sleeping in
dyntick-idle mode).
Lines~46 and 51 acquire and release the root \url{rcu_node} structure's
lock, again to avoid possible confusion with a concurrent end of the
current grace period.
Line~47 checks to see if the current grace period is still in force, and,
if so, line~48 advances the state machine to the \url{RCU_FORCE_QS} state
and line~49 saves the current grace-period number for the benefit of
the next invocation of \url{force_quiescent_state()}.
The reason for saving the current grace-period number is to correctly
handle race conditions involving the current grace period ending
concurrently with the next invocation of \url{force_quiescent_state()}.

As noted earlier, lines~53-58 handle the second and subsequent invocations
of \url{force_quiescent_state()} in \url{CONFIG_NO_HZ} kernels, and \emph{all}
invocations in non-\url{CONFIG_NO_HZ} kernels.
Lines~54 and 58 invoke \url{rcu_process_dyntick()}, which cycles through
the CPUs that have still not passed through a quiescent state, invoking
\url{rcu_implicit_dynticks_qs()} on them, which in turn checks to see
if any of these CPUs have passed through dyntick-idle state (if
\url{CONFIG_NO_HZ} is enabled), checks to see if we are waiting on
any offline CPUs, and finally sends a reschedule IPI to any remaining
CPUs not in the first two groups.

