% appendix/rcuimpl/rcutreewt.tex

% todo...

%DONE% Data structures and module parameters

% External interfaces.
% rcu_check_callbacks, __rcu_process_callbacks, rcu_process_callbacks
%	__call_rcu, call_rcu, call_rcu_bh, __rcu_pending, rcu_pending,
%	rcu_needs_cpu, rcu_cpu_notify, __rcu_init

% initialization, online/offline
% __rcu_offline_cpu, rcu_offline_cpu (empty if !CONFIG_HOTPLUG_CPU)
%	rcu_init_percpu_data, rcu_online_cpu,
%	rcu_init_levelspread (CONFIG_RCU_FANOUT_EXACT and not)
%	rcu_init_one, 

% simple functions: rcu_batches_completed, rcu_batches_completed_bh,
%	cpu_has_callbacks_ready_to_invoke, cpu_needs_another_gp,
%	rcu_get_root,

% rcu_implicit_offline_qs (CONFIG_SMP only)

% rcu_enter_nohz, rcu_exit_nohz, rcu_nmi_enter, rcu_nmi_exit,
%	rcu_irq_enter, rcu_irq_exit -- covered in formal.  Reference.
%	app:formal:Simplicity Avoids Formal Verification
%	Ditto dyntick_save_progress_counter, rcu_implicit_dynticks_qs,
% Cover dyntick_record_completed, dyntick_recall_completed
% Note that dyntick_record_completed() is empty if !CONFIG_NO_HZ.
% Note that dyntick_recall_completed() is subtly different if !CONFIG_NO_HZ.
% Note that dyntick_recall_completed() and rcu_implicit_dynticks_qs are
% 	trivial if !CONFIG_NO_HZ.

% Stall stuff.  record_gp_stall_check_time, print_other_cpu_stall,
%	print_cpu_stall(), check_cpu_stall().
% Note that record_gp_stall_check_time and check_cpu_stall are empty if
%	!CONFIG_RCU_CPU_STALL_DETECTOR

% GP detection.
% note_new_gpnum, check_for_new_grace_period, rcu_start_gp, rcu_process_gp_end,
%	cpu_quiet_msk(), cpu_quiet(), rcu_check_quiescent_state(),
%	rcu_do_batch

\section{Hierarchical RCU Code Walkthrough}
\label{app:rcuimpl:rcutreewt:Hierarchical RCU Code Walkthrough}

This section walks through selected sections of the Linux-kernel
hierarchical RCU code.
As such, this section is intended for hard-core hackers who wish
to understand hierarchical RCU at a very low level.
Hard-core masochists might also be interested in reading this section.

\subsection{Data Structures and Module Parameters}
\label{app:rcuimpl:rcutreewt:Data Structures and Module Parameters}

@@@ roadmap @@@

\subsubsection{Tracking Dyntick State}
\label{app:rcuimpl:rcutreewt:Tracking Dyntick State}

The per-CPU \url{rcu_dynticks} structure tracks dynticks state using the
following fields:

\begin{description}
\item[\url{dynticks_nesting}:]
	This \url{int} counts the number of reasons that the corresponding
	CPU should be monitored for RCU read-side critical sections.
	If the CPU is in dynticks-idle mode, then this counts the
	irq nesting level, otherwise it is one greater than the
	irq nesting level.
\item[\url{dynticks}:]
	This \url{int} counter's value is even if the corresponding CPU is
	in dynticks-idle mode and there are no irq handlers currently
	running on that CPU, otherwise the counter's value is odd.
	In other words, if this counter's value is odd, then the
	corresponding CPU might be in an RCU read-side critical section.
\item[\url{dynticks_nmi}:]
	This \url{int} counter's value is odd if the corresponding CPU is
	in an NMI handler, but only if the NMI arrived while this
	CPU was in dyntick-idle mode with no irq handlers running.
	Otherwise, the counter's value will be even.
\end{description}

This state is shared between the rcu and rcu\_bh implementations.

\subsubsection{Nodes in the Hierarchy}
\label{app:rcuimpl:rcutreewt:Nodes in the Hierarchy}

As noted earlier, the \url{rcu_node} hierarchy is flattened into
the \url{rcu_state} structure as shown in
Figure~\ref{fig:app:rcuimpl:rcutree:Mapping rcu-node Hierarchy Into Array}
on
page~\pageref{fig:app:rcuimpl:rcutree:Mapping rcu-node Hierarchy Into Array}.
Each \url{rcu_node} in this hierarchy has fields as follows:

\begin{description}
\item[\url{lock}:]
	This spinlock guards the non-constant fields in this structure.
	This lock is acquired from softirq context, so must disable
	irqs.

\QuickQuiz{Why not simply disable bottom halves (softirq) when acquiring
	the \url{rcu_data} structure's \url{lock}?
	Wouldn't this be faster?}
\QuickQuizAnswer{
	Because this lock can be acquired from functions
	called by \url{call_rcu()}, which in turn can be
	invoked from irq handlers.
	Therefore, irqs \emph{must} be disabled when
	holding this lock.
} \QuickQuizEnd

	The \url{lock} field of the root \url{rcu_node} has additional
	responsibilities:
	\begin{enumerate}
	\item	Serializes CPU-stall checking, so that a given stall
		is reported by only one CPU.
		This can be important on systems with thousands of
		CPUs!
	\item	Serializes starting a new grace period, so that
		multiple CPUs don't start conflicting grace periods
		concurrently.
	\item	Prevents new grace periods from starting in code that
		needs to run within the confines of a single grace period.
	\item	Serializes the state machine forcing quiescent states
		(in \url{force_quiescent_state()}) in order to
		keep the number of reschedule IPIs down to a dull
		roar.
	\end{enumerate}
\item[\url{qsmask}:]
	This bitmask tracks which CPUs (for leaf \url{rcu_node} structures)
	or groups of CPUs (for non-leaf \url{rcu_node} structures)
	still need to pass through a quiescent state in order for the
	current grace period to end.
\item[\url{qsmaskinit}:]
	This bitmask tracks which CPUs or groups of CPUs will need to
	pass through a quiescent state for subsequent grace periods
	to end.
	The online/offline code manipulates the \url{qsmaskinit} fields,
	which are copied to the corresponding \url{qsmask} fields at
	the beginning of each grace period.
	This copy operation is one reason why grace period initialization
	must exclude online/offline operations.
\item[\url{grpmask}:]
	This bitmask has a single bit set, and that is the bit corresponding
	to the this \url{rcu_node} structure's position in the parent
	\url{rcu_node} structure's \url{qsmask} and \url{qsmaskinit}
	fields.

\QuickQuiz{How about the \url{qsmask} and \url{qsmaskinit}
	fields for the leaf \url{rcu_node} structures?
	Doesn't there have to be some way to work out
	which of the bits in these fields corresponds
	to each CPU covered by the \url{rcu_node} structure
	in question?}
\QuickQuizAnswer{
	Indeed there does!
	The \url{grpmask} field in each CPU's \url{rcu_data}
	structure does this job.
} \QuickQuizEnd

\item[\url{grplo}:]
	This field contains the number of the lowest-numbered CPU covered
	by this \url{rcu_node} structure.
\item[\url{grphi}:]
	This field contains the number of the highest-numbered CPU covered
	by this \url{rcu_node} structure.
\item[\url{grpnum}:]
	This field contains the bit number in the parent \url{rcu_node}
	structure's \url{qsmask} and \url{qsmaskinit} fields that this
	\url{rcu_node} structure corresponds to.
	In otherwords, given a pointer \url{rnp} to a given
	\url{rcu_node} structure, it will always be the case that
	\url{1UL << rnp->grpnum == rnp->grpmask}.
	The \url{grpnum} field is used only for tracing output.
\item[\url{level}:]
	This field contains zero for the root \url{rcu_node} structure,
	one for the \url{rcu_node} structures that are children of
	the root, and so on down the hierarchy.
\item[\url{parent}:]
	This field is a pointer to the parent \url{rcu_node} structure,
	or NULL for the root \url{rcu_node} structure.
\end{description}

\subsection{Per-CPU Data}
\label{app:rcuimpl:rcutreewt:Per-CPU Data}

The \url{rcu_data} structure contains RCU's per-CPU state.
It contains control variables governing grace periods and
quiescent states (\url{completed}, \url{gpnum}, \url{passed_quiesc_completed},
\url{passed_quiesc}, \url{qs_pending}, \url{beenonline}, \url{mynode},
and \url{grpmask}).
The \url{rcu_data} structure also contains control variables pertaining
to RCU callbacks
(\url{nxtlist}, \url{nxttail}, \url{qlen}, and \url{blimit}).
Kernels with dynticks enabled will have relevant control variables in
the \url{rcu_data} structure
(\url{dynticks}, \url{dynticks_snap}, and \url{dynticks_nmi_snap}).
The \url{rcu_data} structure contains event counters used by tracing
(\url{dynticks_fqs} given dynticks, \url{offline_fqs}, and \url{resched_ipi}).
Finally, a pair of fields count calls to \url{rcu_pending()} in order
to determine when to force quiescent states (\url{n_rcu_pending} and
\url{n_rcu_pending_force_qs}), and a \url{cpu} field indicates which
CPU to which a given \url{rcu_data} structure corresponds.

Each of these fields is described below.

\begin{description}
\item[\url{completed}:]
	This field contains the number of the most recent grace period
	that this CPU is aware of having completed.
\item[\url{gpnum}:]
	This field contains the number of the most recent grace period
	that this CPU is aware of having started.
\item[\url{passed_quiesc_completed}:]
	This field contains the number of the grace period that had most
	recently completed when this
	CPU last passed through a quiescent state.
	The "most recently completed" will be from the viewpoint of
	the CPU passing through the quiescent state: if the CPU is
	not yet aware that grace period (say) 42 has completed, it
	will still record the old value of 41.
	This is OK, because the only way that the grace period can
	complete is if this CPU has already passed through a
	quiescent state.
	This field is initialized to a (possibly mythical) past
	grace period number to avoid race conditions when booting
	and when onlining a CPU.
\item[\url{passed_quiesc}:]
	This field indicates whether this CPU has passed
	through a quiescent state since the grace period number
	stored in \url{passed_quiesc_completed} completed.
	This field is cleared each time the corresponding CPU
	becomes aware of the start of a new grace period.
\item[\url{qs_pending}:]
	This field indicates that this CPU is aware that the core
	RCU mechanism is waiting for it to pass through a quiescent state.
	This field is set to one when the CPU detects a new grace
	period or when a CPU is coming online.

\QuickQuiz{But why bother setting \url{qs_pending} to one when a CPU
	is coming online, given that being offline is an extended
	quiescent state that should cover any ongoing grace period?}
\QuickQuizAnswer{
	Because this helps to resolve a race between a CPU coming online
	just as a new grace period is starting.
} \QuickQuizEnd

\QuickQuiz{Why record the last completed grace period number in
	\url{passed_quiesc_completed}?
	Doesn't that cause this RCU implementation to be vulnerable
	to quiescent states seen while no grace period was in progress
	being incorrectly applied to the next grace period that starts?}
\QuickQuizAnswer{
	We record the last completed grace period number in order
	to avoid races where a quiescent state noted near the end of
	one grace period is incorrectly applied to the next grace
	period, especially for dyntick and CPU-offline grace periods.
	Therefore, \url{force_quiescent_state()} and friends all
	check the last completed grace period number to avoid such races.

	Now these dyntick and CPU-offline grace periods are only checked
	for when a grace period is actually active.
	The only quiescent states that can be recorded when no grace
	period is in progress are self-detected quiescent states,
	which are recorded in the \url{passed_quiesc_completed},
	\url{passed_quiesc}, and \url{qs_pending}.
	These variables are initialized every time the corresponding
	CPU notices that a new grace period has started, preventing
	any obsolete quiescent states from being applied to the
	new grace period.

	All that said, optimizing grace-period latency may require that
	\url{gpnum} be tracked in addition to \url{completed}.
} \QuickQuizEnd

\item[\url{beenonline}:]
	This field, initially zero, is set to one whenever the corresponding
	CPU comes online.
	This is used to avoid producing useless tracing output for CPUs
	that never have been online, which is useful in kernels where
	\url{NR_CPUS} greatly exceeds the actual number of CPUs.

\QuickQuiz{What is the point of running a system with \url{NR_CPUS}
	way bigger than the actual number of CPUs?}
\QuickQuizAnswer{
	Because this allows producing a single binary of the Linux kernel
	that runs on a wide variety of systems, greatly easing administration
	and validation.
} \QuickQuizEnd

\item[\url{mynode}:]
	This field is a pointer to the leaf \url{rcu_node} structure that
	handles the corresponding CPU.
\item[\url{grpmask}:]
	This field is a bitmask that has the single bit set that indicates
	which bit in \url{mynode->qsmask} signifies the corresponding CPU.
\item[\url{nxtlist}:]
	This field is a pointer to the oldest RCU callback (\url{rcu_head}
	structure) residing on this CPU, or \url{NULL} if this CPU currently
	has no such callbacks.
	Additional callbacks may be chained via their \url{next} pointers.
\item[\url{nxttail}:]
	This field is an array of double-indirect tail pointers
	into the \url{nxtlist} callback list.
	If \url{nxtlist} is empty, then all of the \url{nxttail} pointers
	directly reference the \url{nxtlist} field.
	Each element of the \url{nxttail} array has meaning as follows:
	\begin{description}
	\item[\url{RCU_DONE_TAIL=0}:]
		This element references the \url{->next} field of
		the last callback that has passed through its grace
		period and is ready to invoke, or references the \url{nxtlist}
		field if there is no such callback.
	\item[\url{RCU_WAIT_TAIL=1}:]
		This element references the \url{next} field of the
		last callback that is waiting for the current grace
		period to end, or is equal to the \url{RCU_DONE_TAIL}
		element if there is no such callback.
	\item[\url{RCU_NEXT_READY_TAIL=2}:]
		This element references the \url{next} field of the
		last callback that is ready to wait for the next
		grace period, or is equal to the \url{RCU_WAIT_TAIL}
		element if there is no such callback.
	\item[\url{RCU_NEXT_TAIL=3}:]
		This element references the \url{next} field of the
		last callback in the list, or references the \url{nxtlist}
		field if the list is empty.
	\end{description}

\QuickQuiz{Why not simply have multiple lists rather than this funny
	multi-tailed list?}
\QuickQuizAnswer{
	Because this multi-tailed approach, due to Lai Jiangshan,
	simplifies callback processing.
} \QuickQuizEnd

\item[\url{qlen}:]
	This field contains the number of callbacks queued on
	\url{nxtlist}.
\item[\url{blimit}:]
	This field contains the maximum number of callbacks that may
	be invoked at a time.
	This limitation improves system responsiveness under heavy load.
\item[\url{dynticks}:]
	This field references the \url{rcu_dynticks} structure for
	the corresponding CPU, which is described in
	Section~\ref{app:rcuimpl:rcutreewt:Tracking Dyntick State}.
\item[\url{dynticks_snap}:]
	This field contains a past value of \url{dynticks->dynticks},
	which is used to detect when a CPU passes through a dynticks
	idle state when this CPU happens to be in an irq
	handler each time that \url{force_quiescent_state()} checks it.
\item[\url{dynticks_nmi_snap}:]
	This field contains a past value of \url{dynticks->dynticks_nmi},
	which is used to detect when a CPU passes through a dynticks
	idle state when this CPU happens to be in an NMI
	handler each time that \url{force_quiescent_state()} checks it.
\item[\url{dynticks_fqs}:]
	This field counts the number of times that some other CPU noted
	a quiescent state on behalf of
	the CPU corresponding to this \url{rcu_data} structure due to
	its being in dynticks-idle mode.
\item[\url{offline_fqs}:]
	This field counts the number of times that some other CPU noted
	a quiescent state on behalf of
	the CPU corresponding to this \url{rcu_data} structure due to
	its being offline.

\QuickQuiz{So some poor CPU has to note quiescent states on behalf of
	each and every offline CPU?
	Yecch!
	Won't that result in excessive overheads in the not-uncommon
	case of a system with a small number of CPUs but a large value
	for \url{NR_CPUS}?}
\QuickQuizAnswer{
	Actually, no it will not!

	Offline CPUs are excluded from both the \url{qsmask} and
	\url{qsmaskinit} bit masks, so RCU normally ignores them.
	However, there are races with online/offline operations that
	can result in an offline CPU having its \url{qsmask} bit set.
	These races must of course be handled correctly, and the way
	they are handled is to permit other CPUs to note that RCU
	is waiting on a quiescent state from an offline CPU.
} \QuickQuizEnd

\item[\url{resched_ipi}:]
	This field counts the number of times that a reschedule IPI
	is sent to the corresponding CPU.
	Such IPIs are sent to CPUs that fail to report passing through
	a quiescent states in a timely manner, but are neither offline
	nor in dynticks idle state.
\item[\url{n_rcu_pending}:]
	This field counts the number of calls to \url{rcu_pending()},
	which is called once per jiffy on non-dynticks-idle CPUs.
\item[\url{n_rcu_pending_force_qs}:]
	This field holds a threshold value for \url{n_rcu_pending}.
	If \url{n_rcu_pending} reaches this threshold, that indicates
	that the current grace period has extended too long, so
	\url{force_quiescent_state()} is invoked to expedite it.
\end{description}

\subsection{RCU Global State}
\label{app:rcuimpl:rcutreewt:RCU Global State}

@@@

\subsection{Forcing Quiescent States}
\label{app:rcuimpl:rcutreewt:Forcing Quiescent States}

Normally, CPUs pass through quiescent states which are duly recorded,
resulting in grace periods ending in a timely manner.
However, any of the following three conditions can prevent CPUs from
passing through quiescent states:

\begin{enumerate}
\item	The CPU is in dyntick-idle state, and is sleeping in a low-power
	mode.
	Although such a CPU is officially in an extended quiescent state,
	because it is not executing instructions, it cannot do anything
	on its own.
\item	The CPU is in the process of coming online, and RCU has been
	informed that it is online, but this CPU is not yet actually
	executing code, nor is it marked as online in \url{cpu_online_map}.
	The current grace period will therefore wait on it, but it cannot
	yet pass through quiescent states on its own.
\item	The CPU is running user-level code, but has avoided
	entering the scheduler for an extended time period.
\end{enumerate}

In each of these cases, RCU needs to take action on behalf of the
non-responding CPU.
This section describes the functions that take such action.

% rcu_process_dyntick

\begin{figure}[htbp]
{ \scriptsize
\begin{verbatim}
  1 static void
  2 force_quiescent_state(struct rcu_state *rsp, int relaxed)
  3 {
  4   unsigned long flags;
  5   long lastcomp;
  6   struct rcu_node *rnp = rcu_get_root(rsp);
  7   u8 signaled;
  8 
  9   if (ACCESS_ONCE(rsp->completed) ==
 10       ACCESS_ONCE(rsp->gpnum))
 11     return;
 12   if (!spin_trylock_irqsave(&rsp->fqslock, flags)) {
 13     rsp->n_force_qs_lh++;
 14     return;
 15   }
 16   if (relaxed &&
 17       (long)(rsp->jiffies_force_qs - jiffies) >= 0)
 18     goto unlock_ret;
 19   rsp->n_force_qs++;
 20   spin_lock(&rnp->lock);
 21   lastcomp = rsp->completed;
 22   signaled = rsp->signaled;
 23   rsp->jiffies_force_qs =
 24     jiffies + RCU_JIFFIES_TILL_FORCE_QS;
 25   if (lastcomp == rsp->gpnum) {
 26     rsp->n_force_qs_ngp++;
 27     spin_unlock(&rnp->lock);
 28     goto unlock_ret;
 29   }
 30   spin_unlock(&rnp->lock);
 31   switch (signaled) {
 32   case RCU_SAVE_DYNTICK:
 33     if (RCU_SIGNAL_INIT != RCU_SAVE_DYNTICK)
 34       break;
 35     if (rcu_process_dyntick(rsp, lastcomp,
 36           dyntick_save_progress_counter))
 37       goto unlock_ret;
 38     spin_lock(&rnp->lock);
 39     if (lastcomp == rsp->completed) {
 40       rsp->signaled = RCU_FORCE_QS;
 41       dyntick_record_completed(rsp, lastcomp);
 42     }
 43     spin_unlock(&rnp->lock);
 44     break;
 45   case RCU_FORCE_QS:
 46     if (rcu_process_dyntick(rsp,
 47           dyntick_recall_completed(rsp),
 48           rcu_implicit_dynticks_qs))
 49       goto unlock_ret;
 50     break;
 51   }
 52 unlock_ret:
 53   spin_unlock_irqrestore(&rsp->fqslock, flags);
 54 }
\end{verbatim}
}
\caption{rcutree {\tt force\_quiescent\_state()} Code}
\label{fig:app:rcuimpl:rcutreewt:Code for rcutree force-quiescent-state}
\end{figure}

Figure~\ref{fig:app:rcuimpl:rcutreewt:Code for rcutree force-quiescent-state}
shows the code for \url{force_quiescent_state()} for
\url{CONFIG_SMP},\footnote{
	For non-\url{CONFIG_SMP}, \url{force_quiescent_state} is a
	simple wrapper around \url{set_need_resched()}.}
which is invoked when RCU feels the need to expedite the current
grace period by forcing CPUs through quiescent states.
RCU feels this need when either:
\begin{enumerate}
\item	the current grace period has gone on for more than three jiffies
	(or as specified by the compile-time value of
	\url{RCU_JIFFIES_TILL_FORCE_QS}), or
\item	a CPU enqueuing an RCU callback via either \url{call_rcu()}
	or \url{call_rcu_bh()} sees more than 10,000 callbacks enqueued
	(or as specified by the boot-time parameter \url{qhimark}).
\end{enumerate}

Lines~9-11 check to see if there is a grace period in progress,
silently exiting if not.
Lines~12-15 attempt to acquire \url{->fqslock}, which prevents concurrent
attempts to expedite a grace period.
The \url{->n_force_qs_lh} counter is incremented when this lock is
already held, and is visible via the \url{fqlh=} field
in the \url{rcuhier} debugfs file when the \url{CONFIG_RCU_TRACE} kernel
parameter is enabled.
Lines~16-18 check to see if it is really necessary to expedite the
current grace period, in other words, if (1) the current CPU has 10,000
RCU callbacks waiting, or (2) at least three jiffies have passed
since either the beginning of the current grace period or since the
last attempt to expedite the current grace period.
Line~19 then counts the number of attempts to expedite the current
grace period.

Lines~20-30 are executed with the root \url{rcu_node} structure's lock
held in order to prevent confusion should the current grace period
happen to end just as we try to expedite it.
Lines~21 and 22 snapshot the \url{->completed} and \url{\signaled} fields,
line~23 sets the soonest time that a subsequent non-relaxed
\url{force_quiescent_state()} will be allowed to actually do
any expediting, and lines~25-29 check to see if the grace period
ended while we were acquiring the \url{rcu_node} structure's lock,
releasing locks and returning if so.

Lines~30-51 drive the \url{force_quiescent_state()} state machine.
If dynticks are enabled (via the \url{CONFIG_NO_HZ} kernel
parameter), the first call
to \url{force_quiescent_state()} in a given grace period will
execute lines~32-44, and the second and subsequent calls will
execute lines~45-50.
On the other hand, if dynticks is not enabled, then all calls to
\url{force_quiescent_state()} will execute lines~45-50.

The purpose of lines~32-44 is to record the current dynticks-idle state
of all CPUs that have not yet passed through a quiescent state, and
to record a quiescent state for any that are currently in dynticks-idle
state (but not currently in an irq or NMI handler).
Lines~33-34 serve to inform gcc that this branch of the switch statement
is dead code for non-\url{CONFIG_NO_HZ} kernels.
Lines 35-37 invoke \url{rcu_process_dyntick()} in order to invoke
\url{dyntick_save_progress_counter()} for each CPU that has not yet
passed through a quiescent state for the current grace period,
exiting \url{force_quiescent_state()} if the grace period ends in
the meantime (possibly due to having found that all the CPUs that
had not yet passed through a quiescent state were sleeping in
dyntick-idle mode).
Lines~38 and 43 acquire and release the root \url{rcu_node} structure's
lock, again to avoid possible confusion with a concurrent end of the
current grace period.
Line~39 checks to see if the current grace period is still in force, and,
if so, line~40 advances the state machine to the \url{RCU_FORCE_QS} state
and line~41 saves the current grace-period number for the benefit of
the next invocation of \url{force_quiescent_state()}.
The reason for saving the current grace-period number is to correctly
handle race conditions involving the current grace period ending
concurrently with the next invocation of \url{force_quiescent_state()}.

As noted earlier, lines~45-50 handle the second and subsequent invocations
of \url{force_quiescent_state()} in \url{CONFIG_NO_HZ} kernels, and \emph{all}
invocations in non-\url{CONFIG_NO_HZ} kernels.
Lines~47 and 48 invoke \url{rcu_process_dyntick()}, which cycles through
the CPUs that have still not passed through a quiescent state, invoking
\url{rcu_implicit_dynticks_qs()} on them, which in turn checks to see
if any of these CPUs have passed through dyntick-idle state (if
\url{CONFIG_NO_HZ} is enabled), checks to see if we are waiting on
any offline CPUs, and finally sends a reschedule IPI to any remaining
CPUs not in the first two groups.

