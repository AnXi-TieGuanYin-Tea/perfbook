% appendix/rcuimpl/toyrcu.tex

\section{``Toy'' RCU Implementations}
\label{app:rcuimpl:``Toy'' RCU Implementations}

The toy RCU implementations in this section are designed not for
high performance, practicality, or any kind of production use,
but rather for clarity.
Nevertheless, you must have a thorough understanding of
Chapters~\ref{chp:Introduction},
\ref{chp:defer:Deferred Processing}, and
\ref{sec:advsync:Advanced Synchronization}
for even these toy RCU implementations to make much sense.

Appendix~\ref{app:rcuimpl:Lock-Based RCU} presents a rudimentary
RCU implementation based on simple locking, while
Appendicies~\ref{app:rcuimpl:Simple Counter-Based RCU} through
\ref{app:rcuimpl:Scalable Counter-Based RCU} present a series of
simple RCU implementations based on a reference counters.

\subsection{Lock-Based RCU}
\label{app:rcuimpl:Lock-Based RCU}

\begin{figure}[bp]
{ \scriptsize
\begin{verbatim}
  1 static void rcu_read_lock(void)
  2 {
  3   spin_lock(&rcu_gp_lock);
  4 }
  5 
  6 static void rcu_read_unlock(void)
  7 {
  8   spin_unlock(&rcu_gp_lock);
  9 }
 10 
 11 void synchronize_rcu(void)
 12 {
 13   spin_lock(&rcu_gp_lock);
 14   spin_unlock(&rcu_gp_lock);
 15 }
\end{verbatim}
}
\caption{Lock-Based RCU Implementation}
\label{fig:app:rcuimpl:Lock-Based RCU Implementation}
\end{figure}

Perhaps the simplest RCU implementation leverages locking, as
shown in
Figure~\ref{fig:app:rcuimpl:Lock-Based RCU Implementation}.
In this implementation, \url{rcu_read_lock()} acquires a global
spinlock, \url{rcu_read_unlock()} releases it, and
\url{synchronize_rcu()} acquires it then immediately releases it.

This implementation has numerous shortcomings, but does faithfully
implement the most basic RCU semantics.
Because \url{synchronize_rcu()} cannot returns until it has acquired
(and released) the lock, it cannot return until all prior RCU read-side
critical sections have completed, thereby releasing the lock so that
\url{synchronize_rcu()} can acquire it.

\QuickQuiz{What are some of the shortcomings of the lock-based
	implementation shown in
	Figure~\ref{fig:app:rcuimpl:Lock-Based RCU Implementation}?}
\QuickQuizAnswer{
	There are a number of serious shortcomings:
	\begin{enumerate}
	\item	The lock operations in \url{rcu_read_lock()} and
		\url{rcu_read_unlock()} are extremely heavyweight.
	\item	These same lock operations permit \url{rcu_read_lock()}
		to participate in deadlock cycles.
	\item	Only a single thread can be in an RCU read-side
		critical section at a time, which negates RCU's
		scalability advantages.
		This could be overcome by using reader-writer
		locking~\cite{PaulMcKenney2005e}, but only for
		unusually long RCU read-side critical sections.
	\item	RCU read-side critical sections cannot be nested.
	\item	Although concurrent RCU updates could in principle be
		satisfied by a common grace period, this implementation
		serializes grace periods, preventing grace-period
		sharing.
	\end{enumerate}
	These shortcomings are problematic for all the reasons
	discussed in Chapter~\ref{chp:Introduction}.
	It is hard to imagine this implementation being useful
	in a production setting, though it does have the virtue
	of being implementable in user-level applications.
} \QuickQuizEnd

The counter-based implementation described next overcomes some of
these shortcomings.

\subsection{Simple Counter-Based RCU}
\label{app:rcuimpl:Simple Counter-Based RCU}

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 atomic_t rcu_refcnt;
  2 
  3 static void rcu_read_lock(void)
  4 {
  5   atomic_inc(&rcu_refcnt);
  6   smp_mb();
  7 }
  8 
  9 static void rcu_read_unlock(void)
 10 {
 11   smp_mb();
 12   atomic_dec(&rcu_refcnt);
 13 }
 14 
 15 void synchronize_rcu(void)
 16 {
 17   smp_mb();
 18   while (atomic_read(&rcu_refcnt) != 0) {
 19     poll(NULL, 0, 10);
 20   }
 21   smp_mb();
 22 }
\end{verbatim}
}
\caption{RCU Implementation Using Single Global Reference Counter}
\label{fig:app:rcuimpl:RCU Implementation Using Single Global Reference Counter}
\end{figure}

A slightly more sophisticated RCU implementation is shown in
Figure~\ref{fig:app:rcuimpl:RCU Implementation Using Single Global Reference Counter}.
This implementation makes use of a global reference counter
\url{rcu_refcnt} defined on line~1.
The \url{rcu_read_lock()} primitive atomically increments this
counter, then executes a memory barrier to ensure that the
RCU read-side critical section is ordered after the atomic
increment.
Similarly, \url{rcu_read_unlock()} executes a memory barrier to
confine the RCU read-side critical section, then atomically
decrements the counter.
The \url{synchronize_rcu()} primitive spins waiting for the reference
counter to reach zero, surrounded by memory barriers.
Again, once \url{synchronize_rcu()} returns, all prior
RCU read-side critical sections are guaranteed to have completed.

In happy contrast to the lock-based implementation shown in
Appendix~\ref{app:rcuimpl:Lock-Based RCU}, this implementation
allows parallel execution of RCU read-side critical sections,
and also allows them to be nested.
In addition, the \url{rcu_read_lock()} primitive cannot possibly
participate in deadlock cycles.

\QuickQuiz{What are some of the shortcomings of the counter-based
	implementation shown in
	Figure~\ref{fig:app:rcuimpl:RCU Implementation Using Single Global Reference Counter}?}
\QuickQuizAnswer{
	There are still some serious shortcomings:
	\begin{enumerate}
	\item	The atomic operations in \url{rcu_read_lock()} and
		\url{rcu_read_unlock()} are still quite  heavyweight.
		This means that the RCU read-side critical sections
		have to be quite long in order to get any real
		read-side parallelism.
	\item	If there are many concurrent \url{rcu_read_lock()}
		and \url{rcu_read_unlock()} operations, there will
		be extreme memory contention on \url{rcu_refcnt},
		resulting in expensive cache misses.
		This further extends the RCU read-side critical-section
		duration required to provide parallel read-side access.
	\item	A large number of RCU readers with long read-side
		critical sections could prevent \url{synchronize_rcu()}
		from ever completing, as the global counter might
		never reach zero.
		This could result in starvation of RCU updates, which
		is unacceptable in production settings.
	\item	Although concurrent RCU updates could in principle be
		satisfied by a common grace period, this implementation
		serializes grace periods, preventing grace-period
		sharing.
	\end{enumerate}
	It is still hard to imagine this implementation being useful
	in a production setting, though it has a bit more potential
	than the lock-based mechanism.
} \QuickQuizEnd

The next section describes a variation on the reference-counting
scheme that is more favorable to writers.

\subsection{Starvation-Free Counter-Based RCU}
\label{app:rcuimpl:Starvation-Free Counter-Based RCU}

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 static void rcu_read_lock(void)
  2 {
  3   int i;
  4   int n;
  5 
  6   n = __get_thread_var(rcu_nesting);
  7   if (n == 0) {
  8     i = atomic_read(&rcu_idx);
  9     __get_thread_var(rcu_read_idx) = i;
 10     atomic_inc(&rcu_refcnt[i]);
 11   }
 12   __get_thread_var(rcu_nesting) = n + 1;
 13   smp_mb();
 14 }
 15 
 16 static void rcu_read_unlock(void)
 17 {
 18   int i;
 19   int n;
 20 
 21   smp_mb();
 22   n = __get_thread_var(rcu_nesting);
 23   if (n == 1) {
 24      i = __get_thread_var(rcu_read_idx);
 25     atomic_dec(&rcu_refcnt[i]);
 26   }
 27   __get_thread_var(rcu_nesting) = n - 1;
 28 }
\end{verbatim}
}
\caption{RCU Read-Side Using Global Reference-Count Pair}
\label{fig:app:rcuimpl:RCU Read-Side Using Global Reference-Count Pair}
\end{figure}

Figure~\ref{fig:app:rcuimpl:RCU Read-Side Using Global Reference-Count Pair}
shows the read-side primitives of an RCU implementation that uses a pair
of reference counters (\url{rcu_refcnt[]}),
along with a global index that
selects one counter out of the pair (\url{rcu_idx}),
a per-thread nesting counter \url{rcu_nesting},
a per-thread snapshot of the global index (\url{rcu_read_idx}),
and a global lock (\url{rcu_gp_lock}).

The \url{rcu_read_lock()} primitive atomically increments the member of the
\url{rcu_refcnt[]} pair indexed by \url{rcu_idx}, and keeps a
snapshot of this index in the per-thread variable \url{rcu_read_idx}.
The \url{rcu_read_unlock()} primitive then atomically decrements
whichever counter of the pair that the corresponding \url{rcu_read_lock()}
incremented.
However, because only one value of \url{rcu_idx} is remembered per thread,
additional measures must be taken to permit nesting.
These additional measures use the per-thread \url{rcu_nesting} variable
to track nesting.

To make all this work, line~6 of \url{rcu_read_lock()} in
Figure~\ref{fig:app:rcuimpl:RCU Read-Side Using Global Reference-Count Pair}
picks up the
current thread's instance of \url{rcu_nesting}, and if line~7 finds
that this is the outermost \url{rcu_read_lock()},
then lines~8-10 pick up the current value of
\url{rcu_idx}, save it in this thread's instance of \url{rcu_read_idx},
and atomically increment the selected element of \url{rcu_refcnt}.
Regardless of the value of \url{rcu_nesting}, line~12 increments it.
Line~13 executes a memory barrier to ensure that the RCU read-side
critical section does not bleed out before the \url{rcu_read_lock()} code.

Similarly, the \url{rcu_read_unlock()} function executes a memory barrier
at line~21
to ensure that the RCU read-side critical section does not bleed out
after the \url{rcu_read_unlock()} code.
Line~22 picks up this thread's instance of \url{rcu_nesting}, and if
line~23 finds that this is the outermost \url{rcu_read_unlock()},
then lines~24 and 25 pick up this thread's instance of \url{rcu_read_idx}
(saved by the outermost \url{rcu_read_lock()}) and atomically decrements
the selected element of \url{rcu_refcnt}.
Regardless of the nesting level, line~27 decrements this thread's
instance of \url{rcu_nesting}.

\begin{figure}[tbp]
{ \scriptsize
\begin{verbatim}
  1 void synchronize_rcu(void)
  2 {
  3   int i;
  4 
  5   smp_mb();
  6   spin_lock(&rcu_gp_lock);
  7   i = atomic_read(&rcu_idx);
  8   atomic_set(&rcu_idx, !i);
  9   smp_mb();
 10   while (atomic_read(&rcu_refcnt[i]) != 0) {
 11     poll(NULL, 0, 10);
 12   }
 13   smp_mb();
 14   atomic_set(&rcu_idx, i);
 15   smp_mb();
 16   while (atomic_read(&rcu_refcnt[!i]) != 0) {
 17     poll(NULL, 0, 10);
 18   }
 19   spin_unlock(&rcu_gp_lock);
 20   smp_mb();
 21 }
\end{verbatim}
}
\caption{RCU Update Using Global Reference-Count Pair}
\label{fig:app:rcuimpl:RCU Update Using Global Reference-Count Pair}
\end{figure}

Figure~\ref{fig:app:rcuimpl:RCU Update Using Global Reference-Count Pair}
shows the corresponding \url{synchronize_rcu()} implementation.
Lines~6 and 19 acquire and release \url{rcu_gp_lock} in order to
prevent more than one concurrent instance of \url{synchronize_rcu()}.
Lines~7-8 pick up the value of \url{rcu_idx} and complement it,
respectively, so that subsequent instances of \url{rcu_read_lock()}
will use a different element of \url{rcu_idx} that did preceding
instances.
Lines~10-12 then wait for the prior element of \url{rcu_idx} to
reach zero, with the memory barrier on line~9 ensuring that the check
of \url{rcu_idx} is not reordered to precede the complementing of
\url{rcu_idx}.
Lines~13-18 repeat this process, and line~20 ensures that any
subsequent reclamation operations are not reordered to precede the
checking of \url{rcu_refcnt}.

\QuickQuiz{Why the memory barrier on line~5 of \url{synchronize_rcu()} in
	Figure~\ref{fig:app:rcuimpl:RCU Update Using Global Reference-Count Pair}
	given that there is a spin-lock acquisition immediately after?}
\QuickQuizAnswer{
	The spin-lock acquisition only guarantees that the spin-lock's
	critical section will not ``bleed out'' to precede the
	acquisition.
	It in no way guarantees that code preceding the spin-lock
	acquisitoin won't be reordered into the critical section.
	Such reordering could cause a removal from an RCU-protected
	list to be reordered to follow the complementing of
	\url{rcu_idx}, which could allow a newly starting RCU
	read-side critical section to see the recently removed
	data element.

	Exercise for the reader: use a tool such as Promela/spin
	to determine which (if any) of the memory barriers in
	Figure~\ref{fig:app:rcuimpl:RCU Update Using Global Reference-Count Pair}
	are really needed.
	See Section~\ref{sec:analysis:Using Promela and Spin to Verify Parallel Algorithms}
	for information on using these tools.
	The first correct and complete response will be credited.
} \QuickQuizEnd

\QuickQuiz{Why is the counter flipped twice in
	Figure~\ref{fig:app:rcuimpl:RCU Update Using Global Reference-Count Pair}?
	Shouldn't a single flip-and-wait cycle be sufficient?}
\QuickQuizAnswer{
	Both flips are absolutely required.
	To see this, consider the following sequence of events:
	\begin{enumerate}
	\item	Line~8 of \url{rcu_read_lock()} in
		Figure~\ref{fig:app:rcuimpl:RCU Read-Side Using Global Reference-Count Pair}
		picks up \url{rcu_idx}, finding its value to be zero.
	\item	Line~8 of \url{synchronize_rcu()} in
		Figure~\ref{fig:app:rcuimpl:RCU Update Using Global Reference-Count Pair}
		complements the value of \url{rcu_idx}, setting its
		value to one.
	\item	Lines~10-13 of \url{synchronize_rcu()} find that the
		value of \url{rcu_refcnt[0]} is zero, and thus
		returns.
		(Recall that the question is asking what happens if
		lines~14-20 are omitted.)
	\item	Lines~9 and 10 of \url{rcu_read_lock()} store the
		value zero to this thread's instance of \url{rcu_read_idx}
		and increments \url{rcu_refcnt[0]}, respectively.
		Execution then proceeds into the RCU read-side critical
		section.
		\label{app:rcuimpl:rcu_rcgp:RCU Read Side Start}
	\item	Another instance of \url{synchronize_rcu()} again complements
		\url{rcu_idx}, this time setting its value to zero.
		Because \url{rcu_refcnt[1]} is zero, \url{synchronize_rcu()}
		returns immediately.
		(Recall that \url{rcu_read_lock()} incremented
		\url{rcu_refcnt[0]}, not \url{rcu_refcnt[1]}!)
		\label{app:rcuimpl:rcu_rcgp:RCU Grace Period Start}
	\item	The grace period that started in
		step~\ref{app:rcuimpl:rcu_rcgp:RCU Grace Period Start}
		has been allowed to end, despite
		the fact that the RCU read-side critical section
		that started beforehand in
		step~\ref{app:rcuimpl:rcu_rcgp:RCU Read Side Start}
		has not completed.
		This violates RCU semantics, and could allow the update
		to free a data element that the RCU read-side critical
		section was still referencing.
	\end{enumerate}

	Exercise for the reader: What happens if \url{rcu_read_lock()}
	is preempted for a very long time (hours!) just after
	line~8?
	Does this implementation operate correctly in that case?
	Why or why not?
	The first correct and complete response will be credited.
} \QuickQuizEnd

This implementation avoids the update-starvation issues that could
occur in the single-counter implementation shown in
Figure~\ref{fig:app:rcuimpl:RCU Implementation Using Single Global Reference Counter}.

\QuickQuiz{What are some of the remaining shortcomings of the
	counter-pair-based implementation shown in
	Figures~\ref{fig:app:rcuimpl:RCU Read-Side Using Global Reference-Count Pair}
	and \ref{fig:app:rcuimpl:RCU Update Using Global Reference-Count Pair}?}
\QuickQuizAnswer{
	There are still some serious shortcomings:
	\begin{enumerate}
	\item	The atomic operations in \url{rcu_read_lock()} and
		\url{rcu_read_unlock()} are still quite heavyweight,
		in fact, they are more complex than those of the
		single-counter variant shown in
		Figure~\ref{fig:app:rcuimpl:RCU Implementation Using Single Global Reference Counter}.
		This means that the RCU read-side critical sections
		have to be quite long in order to get any real
		read-side parallelism.
	\item	If there are many concurrent \url{rcu_read_lock()}
		and \url{rcu_read_unlock()} operations, there will
		be extreme memory contention on the \url{rcu_refcnt}
		elements, resulting in expensive cache misses.
		This further extends the RCU read-side critical-section
		duration required to provide parallel read-side access.
	\item	The need to flip \url{rcu_idx} twice imposes substantial
		overhead on updates, especially if there are large
		numbers of threads.
	\item	Although concurrent RCU updates could in principle be
		satisfied by a common grace period, this implementation
		serializes grace periods, preventing grace-period
		sharing.
	\end{enumerate}
	Despite these shortcomings, one could imagine this variant
	of RCU being used on small tightly coupled multiprocessors.
	However, it would not not likely scale well beyond a few CPUs.
} \QuickQuizEnd

The next section describes yet another variation on the reference-counting
scheme with greatly improved scalability.

\subsection{Scalable Counter-Based RCU}
\label{app:rcuimpl:Scalable Counter-Based RCU}

\subsection{Scalable Counter-Based RCU}
\label{app:rcuimpl:Scalable Counter-Based RCU}

