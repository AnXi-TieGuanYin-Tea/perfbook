% defer/defer.tex

\QuickQuizChapter{chp:Deferred Processing}{Deferred Processing}

The strategy of deferring work goes back before the dawn of recorded
history. It has occasionally been derided as procrastination or
even as sheer laziness.
However, in the last few decades workers have recognized this strategy's value
in simplifying and streamlining parallel algorithms~\cite{Kung80,HMassalinPhD}.
Believe it or not, ``laziness'' in parallel programming often outperforms and
out-scales industriousness!
These performance and scalability benefits stem from the fact that
deferring work often enables weakening of synchronization primitives,
thereby reducing synchronization overhead.
General approaches work deferral include
reference counting (Section~\ref{sec:defer:Reference Counting}),
hazard pointesr (Section~\ref{sec:defer:Hazard Pointers}),
sequence locking (Section~\ref{sec:defer:Sequence Locks}),
and RCU (Section~\ref{sec:defer:Read-Copy Update (RCU)}).

This chapter will use a simplified demultiplexing algorithm to demonstrate
the value of these approaches and to allow them to be compared.
Demultiplexing algorithms are used in operating-system kernels to
deliver each incomoing TCP/IP packets to its receiving process.
This particular algorithm is a simplified version of the classic 1980s
packet-train-optimized algorithm used in BSD UNIX~\cite{VanJacobson88},
consisting of a simple linked list.
Modern demultiplexing algorithms use more complex data structures,
for example, hash tables~\cite{McKenney92b}, however, as in
Chapter~\ref{chp:Counting}, an extremely simple algorithm will
help highlight isses specific to parallelism in an extremely
easy-to-understand setting.

We further simplify the algorithm by reducing the search key from
a quadruple consisting of source and destination IP addresses and
ports all the down to a simple integer.
The value looked up and returned will also be a simple integer,
so that the data structure is as shown in
Figure~\ref{fig:defer:Packet Demultiplexing List}, which
directs packets of address~42 to process~1, address~56 to
process~2, and address~17 to process~10.
Assuming that processes are long-lived and receive a large number
of packets, this list will be searched frequently and updated
rarely.
In Chapter~\ref{chp:Hardware and its Habits}
we learned that @@@

\begin{figure}[tb]
\begin{center}
\resizebox{3in}{!}{\includegraphics{defer/DemuxList}}
\end{center}
\caption{Packet Demultiplexing List}
\label{fig:defer:Packet Demultiplexing List}
\end{figure}

\input{defer/refcnt}
\input{defer/hazptr}
\input{defer/seqlock}
\input{defer/rcu}
\input{defer/rcuexercises}
\input{defer/whichtochoose}
\input{defer/updates}

% @@@ compare and contrast the various mechanisms.
